===== SCRIPT SNAPSHOT BEGIN =====
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2025/11/22
# @Author  : Joyful Buffalo
# @File    : simple_ctc_asr.py
# !/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import annotations

import json
import math
import random
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Tuple, Optional, Iterator, cast

import numpy as np
import torch
import torchaudio
from torch import nn
from torch.nn import functional as F
from torch.nn.attention import sdpa_kernel, SDPBackend
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import Dataset, DataLoader, Sampler
from torchaudio.compliance import kaldi
from tqdm import tqdm
from utils.specAug import SpecAugment


@dataclass
class ASRConfig:
    train_manifest: str
    dev_manifest: str
    sample_rate: int = 16000
    num_mel_bins: int = 80
    frame_length_ms: float = 25.0
    frame_shift_ms: float = 10.0
    dither: float = 0.0
    hidden_size: int = 256
    layers: int = 2
    dropout: float = 0.1
    batch_size: Optional[int] = None
    max_frames_per_batch: Optional[int] = 8192
    num_epochs: int = 10
    learning_rate: float = 1e-3
    weight_decay: float = 1e-5
    max_grad_norm: float = 5.0
    num_workers: int = 4
    prefetch_factor: int = 1
    bucket_size: int = 100
    pin_memory: bool = True
    shuffle: bool = True


# ======================
# 动态batch采样器
# ======================
class LengthBucketBatchSampler(Sampler[List[int]]):
    """按长度分桶的动态batch采样器，支持固定batch_size或max_frames_per_batch"""

    def __init__(
            self,
            lengths: List[int],
            batch_size: Optional[int] = None,
            max_frames_per_batch: Optional[int] = None,
            shuffle: bool = True,
            bucket_size: int = 100,
    ):
        super(LengthBucketBatchSampler, self).__init__(None)
        assert (batch_size is None) ^ (max_frames_per_batch is None), \
            "Exactly one of batch_size or max_frames_per_batch should be provided."
        self.lengths = lengths
        self.batch_size = batch_size
        self.max_frames_per_batch = max_frames_per_batch
        self.shuffle = shuffle
        self.bucket_size = bucket_size
        self._indices = list(range(len(lengths)))
        self.g = torch.Generator().manual_seed(torch.seed())

    def __iter__(self) -> Iterator[List[int]]:
        # 返回 batch indices
        if self.shuffle:
            indices = [self._indices[i] for i in torch.randperm(len(self._indices), generator=self.g).tolist()]
        else:
            indices = self._indices

        # 分桶 + 桶内按长度升序
        buckets = [
            indices[i:i + self.bucket_size]
            for i in range(0, len(indices), self.bucket_size)
        ]
        for b in buckets:
            b.sort(key=lambda i: self.lengths[i])

        flat = [i for b in buckets for i in b]

        if self.batch_size is not None:
            for i in range(0, len(flat), self.batch_size):
                yield flat[i:i + self.batch_size]
        else:
            current, cur_frames = [], 0
            for i in flat:
                length = int(self.lengths[i])
                if len(current) > 0 and (cur_frames + length) > int(self.max_frames_per_batch):
                    yield current
                    current, cur_frames = [], 0
                current.append(i)
                cur_frames += length
            if len(current) > 0:
                yield current

    def __len__(self) -> int:
        if self.batch_size is not None:
            return math.ceil(len(self.lengths) / self.batch_size)
        # max_frames 模式下，__len__ 很难精确；给出近似上界
        avg = (sum(self.lengths) / max(1, len(self.lengths)))
        return max(1, int(sum(self.lengths) / max(self.max_frames_per_batch, cast(int, avg))))


# ======================
# 字级 tokenizer（0 留给 CTC blank）
# ======================
class CharTokenizer:
    """最简单的“字级”分词器，0 号留给 CTC blank。"""

    def __init__(self, char2id: Dict[str, int]) -> None:
        self.blank_id: int = 0
        self.char2id: Dict[str, int] = char2id
        # id2char 索引 0 为 <blank>，其余按 id 排序
        self.id2char: List[str] = ["<blank>"] + [
            ch for ch, _ in sorted(char2id.items(), key=lambda x: x[1])
        ]

    @classmethod
    def build_from_jsonl(cls, manifest_path: str) -> "CharTokenizer":
        chars: set[str] = set()
        path = Path(manifest_path)
        with path.open("r", encoding="utf-8") as f:
            for line in f:
                if not line.strip():
                    continue
                item = json.loads(line)
                # 支持 txt 或 text 两种字段名
                txt = item.get("txt") or item.get("text")
                if txt is None:
                    raise ValueError("每行 json 需要包含 'txt' 或 'text' 字段")
                for ch in txt:
                    if ch.isspace():
                        continue  # 去掉空格
                    chars.add(ch)
        # 按字典序排序，id 从 1 开始分配，0 保留给 blank
        char2id: Dict[str, int] = {}
        next_id = 1
        for ch in sorted(chars):
            char2id[ch] = next_id
            next_id += 1
        return cls(char2id)

    @property
    def vocab_size(self) -> int:
        # 包含 blank
        return 1 + len(self.char2id)

    def encode(self, text: str) -> List[int]:
        ids: List[int] = []
        for ch in text:
            if ch.isspace():
                continue
            idx = self.char2id.get(ch)
            if idx is None:
                # 简单处理：丢弃未登录字（也可以映射到 <unk>，这里先偷懒）
                continue
            ids.append(idx)
        return ids

    def decode_ids(self, ids: List[int]) -> str:
        chars: List[str] = []
        for idx in ids:
            if idx == self.blank_id:
                continue
            if 0 <= idx < len(self.id2char):
                ch = self.id2char[idx]
                if ch not in ("<blank>", "<unk>"):
                    chars.append(ch)
        return "".join(chars)


class JsonlASRDataset(Dataset):
    """读取 jsonl 格式清单：{"key":..., "wav":..., "txt":...} 或 {"key":..., "feat":..., "txt":..., "feat_frames":...}"""

    def __init__(self, manifest_path: str, tokenizer: CharTokenizer, config: ASRConfig,
                 compute_lengths: bool = False, use_precomputed_fbank: bool = False) -> None:
        super().__init__()
        self.manifest_path = Path(manifest_path)
        self.tokenizer = tokenizer
        self.sample_rate = config.sample_rate
        self.num_mel_bins = config.num_mel_bins
        self.frame_length_ms = config.frame_length_ms
        self.frame_shift_ms = config.frame_shift_ms
        self.dither = config.dither
        self.compute_lengths = compute_lengths
        self.use_precomputed_fbank = use_precomputed_fbank
        # self.aug = SpecAugment(
        #     freq_mask_param=10,
        #     num_freq_masks=2,
        #     time_mask_param=50,
        #     num_time_masks=2,
        #     protect_last=False,
        # )

        self.entries: List[Dict[str, Any]] = []
        self.lengths: List[int] = []

        with self.manifest_path.open("r", encoding="utf-8") as f:
            for line in f:
                if not line.strip():
                    continue
                item = json.loads(line)
                txt = item.get("txt") or item.get("text")
                if txt is None:
                    raise ValueError("清单每行必须包含 'txt'/'text'")

                # 判断是使用预处理的fbank还是原始wav
                if use_precomputed_fbank:
                    feat = item.get("feat")
                    # if random.random()< 0.5:
                    #     feat = self.aug(feat)
                    if feat is None:
                        raise ValueError("使用预处理fbank时，清单每行必须包含 'feat'")
                    self.entries.append({"feat": feat, "txt": txt})

                    # 如果需要计算长度（用于动态batch）
                    if compute_lengths:
                        feat_frames = item.get("feat_frames", 0)
                        if feat_frames > 0:
                            self.lengths.append(feat_frames)
                        else:
                            print(f"警告: {feat} 没有帧数信息，使用默认值")
                            self.lengths.append(100)
                else:
                    wav = item.get("wav")
                    if wav is None:
                        raise ValueError("清单每行必须包含 'wav'")
                    self.entries.append({"wav": wav, "txt": txt})

                    # 如果需要计算长度（用于动态batch）
                    if compute_lengths:
                        # 从JSON中读取时长（秒），计算特征帧数
                        duration_sec = item.get("length", 0.0)
                        if duration_sec > 0:
                            duration_ms = duration_sec * 1000
                            feat_frames = int((duration_ms - self.frame_length_ms) / self.frame_shift_ms) + 1
                            self.lengths.append(max(1, feat_frames))
                        else:
                            # 如果没有时长信息，给一个默认值
                            print(f"警告: {wav} 没有时长信息，使用默认值")
                            self.lengths.append(100)

        if not self.entries:
            raise RuntimeError(f"{self.manifest_path} 为空")

    def __len__(self) -> int:
        return len(self.entries)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, str]:
        item = self.entries[idx]
        text: str = item["txt"]

        if self.use_precomputed_fbank:
            # 使用预处理好的fbank特征
            feat_path = item["feat"]
            # 使用 numpy 加载更快（特别是在 WSL2 中）
            if feat_path.endswith('.npy'):
                feat = torch.from_numpy(np.load(feat_path))
            else:
                # 兼容 .pt 格式，使用 weights_only 更快更安全
                feat = torch.load(feat_path, weights_only=False)  # (frames, num_mel_bins)
        else:
            # 实时计算fbank特征
            wav_path = item["wav"]
            waveform, sr = torchaudio.load(wav_path)  # (channels, num_samples)
            if waveform.size(0) > 1:
                waveform = waveform.mean(dim=0, keepdim=True)

            if sr != self.sample_rate:
                resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.sample_rate)
                waveform = resampler(waveform)
                sr = self.sample_rate

            # 4) 与 Kaldi 一致，将 [-1, 1] 量化到 16bit 整数范围
            #    这个写法直接参考 WeNet 官方的 compute_fbank 实现:contentReference[oaicite:5]{index=5}
            waveform = waveform * (1 << 15)

            # 5) 计算 fbank（API 见 torchaudio.compliance.kaldi.fbank 官方文档:contentReference[oaicite:6]{index=6}）
            feat = kaldi.fbank(
                waveform,
                num_mel_bins=self.num_mel_bins,
                frame_length=self.frame_length_ms,
                frame_shift=self.frame_shift_ms,
                dither=self.dither,
                energy_floor=0.0,
                sample_frequency=float(sr),
            )  # (frames, num_mel_bins)

        # 文本转为 id 序列
        target_ids = torch.tensor(self.tokenizer.encode(text), dtype=torch.long)
        return feat, target_ids, text


def asr_collate_fn(
        batch: List[Tuple[torch.Tensor, torch.Tensor, str]]
) -> Dict[str, Any]:
    feats, targets, texts = zip(*batch)

    # 对 fbank 按时间维做 padding
    feat_lengths = torch.tensor([f.size(0) for f in feats], dtype=torch.long)
    padded_feats = pad_sequence(feats, batch_first=True)  # (B, T_max, D)

    # 标签拼接成一维向量 + 长度
    target_lengths = torch.tensor([t.size(0) for t in targets], dtype=torch.long)
    concatenated_targets = torch.cat(targets, dim=0)  # (sum_target,)

    return {
        "feats": padded_feats,
        "feat_lengths": feat_lengths,
        "max_feat_lengths": feat_lengths.max().item(),
        "targets": concatenated_targets,
        "target_lengths": target_lengths,
        "texts": list(texts),
    }


class CTCConformer(nn.Module):
    def __init__(
            self,
            input_dim: int,
            vocab_size: int,
            hidden_size: int = 512,
            num_layers: int = 6,
            dropout: float = 0.1,
    ) -> None:
        super().__init__()
        self.input_proj = nn.Sequential(
            nn.Linear(input_dim, input_dim * 4),
            nn.ReLU(inplace=True),
            nn.Linear(input_dim * 4, input_dim * 2)
        )
        self.conformer = torchaudio.models.Conformer(
            input_dim=input_dim * 2,
            num_layers=num_layers,
            ffn_dim=hidden_size,
            dropout=dropout,
            depthwise_conv_kernel_size=15,
            num_heads=8
        )
        self.fc = nn.Linear(input_dim * 2, vocab_size)

    def forward(self, feats: torch.Tensor, feat_lengths, max_length) -> torch.Tensor:
        feats = self.input_proj(feats)
        x, _ = self.conformer(feats, feat_lengths)  # (B, T, 2H)
        logits = self.fc(x)  # (B, T, V)
        return logits


def ctc_greedy_decode(
        logit_batch: torch.Tensor,
        feat_lengths: torch.Tensor,
        blank_id: int,
) -> List[List[int]]:
    """
    最简单 CTC 贪心解码：按时间取 argmax，然后压缩重复 & 去掉 blank。
    logit_batch: (B, T, V)
    feat_lengths: (B,)
    """
    with torch.no_grad():
        probs = F.log_softmax(logit_batch, dim=-1)
        pred_ids = torch.argmax(probs, dim=-1)  # (B, T)

    results: List[List[int]] = []
    for b in range(pred_ids.size(0)):
        length = int(feat_lengths[b].item())
        seq = pred_ids[b, :length].tolist()
        collapsed: List[int] = []
        prev = blank_id
        for idx in seq:
            if idx != blank_id and idx != prev:
                collapsed.append(idx)
            prev = idx
        results.append(collapsed)
    return results


def char_edit_distance(ref: str, hyp: str) -> int:
    """标准 Levenshtein 编辑距离（以“字”为单位）"""
    ref_chars = list(ref)
    hyp_chars = list(hyp)
    n = len(ref_chars)
    m = len(hyp_chars)
    if n == 0:
        return m
    if m == 0:
        return n
    # DP 矩阵大小 (n+1) x (m+1)
    dp = [[0] * (m + 1) for _ in range(n + 1)]
    for i in range(n + 1):
        dp[i][0] = i
    for j in range(m + 1):
        dp[0][j] = j
    for i in range(1, n + 1):
        for j in range(1, m + 1):
            cost = 0 if ref_chars[i - 1] == hyp_chars[j - 1] else 1
            dp[i][j] = min(
                dp[i - 1][j] + 1,  # 删除
                dp[i][j - 1] + 1,  # 插入
                dp[i - 1][j - 1] + cost,  # 替换
            )
    return dp[n][m]


def evaluate_cer(
        model: nn.Module,
        dataloader: DataLoader,
        tokenizer: CharTokenizer,
        device: torch.device,
        ctc_loss: nn.CTCLoss,
) -> tuple[float, float]:
    model.eval()
    total_edit = 0
    total_chars = 0
    total_loss = 0
    total_frame = 0
    with torch.no_grad():
        for batch in tqdm(dataloader, ncols=100):
            feats = batch["feats"].to(device)
            feat_lengths = batch["feat_lengths"].to(device)
            texts = batch["texts"]
            targets = batch["targets"].to(device, non_blocking=True)
            max_length = batch["max_feat_lengths"]
            target_lengths = batch["target_lengths"].to(device, non_blocking=True)
            logits = model(feats, feat_lengths, max_length)  # (B, T, V)
            log_probs = F.log_softmax(logits, dim=-1).transpose(0, 1)
            loss = ctc_loss(log_probs, targets, feat_lengths, target_lengths)
            pred_id_seqs = ctc_greedy_decode(logits, feat_lengths, tokenizer.blank_id)
            batch_frame = int(feat_lengths.sum().item())
            total_loss += loss.item() * batch_frame
            total_frame += batch_frame
            for ref_text, pred_ids in zip(texts, pred_id_seqs):
                hyp_text = tokenizer.decode_ids(pred_ids)
                # 这里也去掉 ref 中的空白字符
                ref = "".join(ch for ch in ref_text if not ch.isspace())
                edit = char_edit_distance(ref, hyp_text)
                total_edit += edit
                total_chars += len(ref)
    if total_chars == 0:
        return 0.0, 0.
    return total_edit / total_chars, total_loss / total_frame


aug = SpecAugment(
    freq_mask_param=10,  # F = 10
    num_freq_masks=2,  # mF = 2
    time_mask_param=50,  # T = 50（帧）
    num_time_masks=2,  # mT = 2
    protect_last=False,
)


def train_one_epoch(
        model: nn.Module,
        dataloader: DataLoader,
        optimizer: torch.optim.Optimizer,
        ctc_loss: nn.CTCLoss,
        device: torch.device,
        max_grad_norm: float,
        tokenizer: CharTokenizer,
) -> float:
    model.train()
    total_loss = 0.0
    total_frames = 0
    total_edit = 0
    total_chars = 0
    idx = 0
    for batch in tqdm(dataloader, ncols=100, position=1):
        feats = batch["feats"].to(device, non_blocking=True)
        feat_lengths = batch["feat_lengths"].to(device, non_blocking=True)
        targets = batch["targets"].to(device, non_blocking=True)
        target_lengths = batch["target_lengths"].to(device, non_blocking=True)
        max_length = batch["max_feat_lengths"]
        if random.random() < 0.1:
            feats = aug(feats)

        optimizer.zero_grad(set_to_none=True)
        with torch.autocast(device_type='cuda', dtype=torch.bfloat16):
            logits = model(feats, feat_lengths, max_length)  # (B, T, V)
            # CTCLoss 官方文档要求 log_probs 形状为 (T, N, C):contentReference[oaicite:7]{index=7}
            log_probs = F.log_softmax(logits, dim=-1).transpose(0, 1)

        loss = ctc_loss(log_probs, targets, feat_lengths, target_lengths)
        loss.backward()
        if max_grad_norm > 0.0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
        optimizer.step()

        batch_frames = int(feat_lengths.sum().item())
        total_loss += loss.item() * batch_frames
        total_frames += batch_frames
        if idx % 100 == 0:
            with torch.no_grad():
                pred_id_seqs = ctc_greedy_decode(logits, feat_lengths, tokenizer.blank_id)
                offset = 0
                for b, pred_ids in enumerate(pred_id_seqs):
                    cur_len = int(target_lengths[b].item())
                    tgt_ids = targets[offset:offset + cur_len].tolist()
                    offset += cur_len
                    ref_text = tokenizer.decode_ids(tgt_ids)
                    hyp_text = tokenizer.decode_ids(pred_ids)
                    edit = char_edit_distance(ref_text, hyp_text)
                    total_edit += edit
                    total_chars += len(ref_text)
        idx += 1
    print(f'train_loss: {total_loss / total_frames:.3f} train cer: {total_edit / total_chars:.3f}')
    if total_frames == 0:
        return 0.0
    return total_loss / total_frames


def dynamic_pre_compile(train_loader, device, model, max_T):
    warmup_batch = next(iter(train_loader))
    warmup_feats = warmup_batch["feats"].to(device)  # (B, T, D)
    warmup_feat_lengths = warmup_batch["feat_lengths"].to(device)
    warmup_max_len = int(warmup_feat_lengths.max().item())

    torch._dynamo.mark_dynamic(warmup_feats, 1, min=1, max=int(max_T))
    model = torch.compile(model)
    with torch.no_grad():
        _ = model(warmup_feats, warmup_feat_lengths, warmup_max_len)
    return model


def main() -> None:
    import time, sys, atexit
    run_dir = Path("logs") / time.strftime("%Y%m%d-%H%M%S")
    run_dir.mkdir(parents=True, exist_ok=True)
    log_f = open(run_dir / "stdout.log", "w", encoding="utf-8", buffering=1)
    try:
        src = Path(__file__).read_text(encoding="utf-8")
    except Exception as e:
        src = f"<FAILED TO READ __file__: {e}>"
    print("===== SCRIPT SNAPSHOT BEGIN =====", file=log_f)
    print(src, file=log_f)
    print("===== SCRIPT SNAPSHOT END =====", file=log_f)
    log_f.flush()
    class _Tee:
        def __init__(self, *fs): self.fs = fs
        def write(self, s):
            for f in self.fs:
                f.write(s); f.flush()
        def flush(self):
            for f in self.fs:
                f.flush()
    sys.stdout = _Tee(sys.__stdout__, log_f)
    atexit.register(log_f.close)
    print(f"[log] run_dir={run_dir.resolve()}")

    torch.set_float32_matmul_precision('high')
    config = ASRConfig(
        train_manifest="dataset/train_fbank_relpath.jsonl",
        dev_manifest="dataset/dev_fbank_relpath.jsonl",
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("使用设备:", device)

    # === 1. 根据训练集构建"字级"词表 ===
    print("构建字级词表...")
    tokenizer = CharTokenizer.build_from_jsonl(config.train_manifest)
    print("vocab_size (含 blank):", tokenizer.vocab_size)

    # === 2. 构建 Dataset / DataLoader ===
    print("构建数据集...")
    train_dataset = JsonlASRDataset(config.train_manifest, tokenizer, config, compute_lengths=True, use_precomputed_fbank=True)
    dev_dataset = JsonlASRDataset(config.dev_manifest, tokenizer, config, compute_lengths=True, use_precomputed_fbank=True)

    # 创建动态batch采样器
    print("创建动态batch采样器...")
    train_sampler = LengthBucketBatchSampler(
        lengths=train_dataset.lengths,
        batch_size=config.batch_size,
        max_frames_per_batch=config.max_frames_per_batch,
        shuffle=config.shuffle,
        bucket_size=config.bucket_size,
    )
    dev_sampler = LengthBucketBatchSampler(
        lengths=dev_dataset.lengths,
        batch_size=config.batch_size,
        max_frames_per_batch=config.max_frames_per_batch,
        shuffle=False,
        bucket_size=config.bucket_size,
    )

    train_loader = DataLoader(
        train_dataset,
        batch_sampler=train_sampler,
        num_workers=config.num_workers,
        pin_memory=config.pin_memory,
        collate_fn=asr_collate_fn,
        prefetch_factor=config.prefetch_factor,
    )
    dev_loader = DataLoader(
        dev_dataset,
        batch_sampler=dev_sampler,
        num_workers=config.num_workers,
        pin_memory=config.pin_memory,
        collate_fn=asr_collate_fn,
        prefetch_factor=config.prefetch_factor,
    )
    # === 3. 构建模型 / 损失 / 优化器 ===
    input_dim = config.num_mel_bins
    vocab_size = tokenizer.vocab_size
    model = CTCConformer(
        input_dim=input_dim,
        vocab_size=vocab_size,
        hidden_size=config.hidden_size,
        num_layers=config.layers,
        dropout=config.dropout,
    ).to(device)

    ctc_loss = nn.CTCLoss(
        blank=tokenizer.blank_id,
        reduction="mean",
        zero_infinity=True,
    )
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.learning_rate,
        weight_decay=config.weight_decay,
        fused=True
    )
    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer,
        mode="min",
        patience=3,
        factor=0.5,
    )
    best_cer = 1.0
    best_path = Path(f"saved_models/best_ctc_asr_cer_{time.strftime("%Y%m%d-%H%M%S")}.pt")

    epoch = 1

    max_T = max(train_dataset.lengths) if train_dataset.lengths else 2048
    model = dynamic_pre_compile(train_loader, device, model, max_T=max_T)
    with sdpa_kernel(SDPBackend.MATH):
        while True:
            train_loss = train_one_epoch(
                model,
                train_loader,
                optimizer,
                ctc_loss,
                device,
                config.max_grad_norm,
                tokenizer
            )
            cer, loss = evaluate_cer(model, dev_loader, tokenizer, device, ctc_loss)
            print(
                f"[Epoch {epoch:02d}] dev_loss_per_frame={loss:.4f}, "
                f"dev_CER={cer * 100:.2f}%"
            )
            old_lr = optimizer.param_groups[0]["lr"]
            lr_scheduler.step(loss)
            new_lr = optimizer.param_groups[0]["lr"]
            if new_lr < old_lr:
                print(f'old_lr={old_lr}, new_lr={new_lr}')
            if cer < best_cer:
                best_cer = cer
                torch.save(
                    {
                        "model_state_dict": model.state_dict(),
                        "config": config.__dict__,
                        "char2id": tokenizer.char2id,
                        "blank_id": tokenizer.blank_id,
                    },
                    best_path,
                )
                print(f"  CER 改善，已保存到 {best_path} (best_CER={best_cer * 100:.2f}%)")
            # torch.cuda.empty_cache()
            alloc = torch.cuda.memory_allocated() / 1024**2
            resv  = torch.cuda.memory_reserved()  / 1024**2
            print(f"allocated={alloc:.1f}MB reserved={resv:.1f}MB")

            epoch += 1


if __name__ == "__main__":
    main()

===== SCRIPT SNAPSHOT END =====
[log] run_dir=/home/lhc/data/gudsen/asr/logs/20251227-070230
使用设备: cuda
构建字级词表...
vocab_size (含 blank): 4231
构建数据集...
创建动态batch采样器...
train_loss: 4.984 train cer: 1.010
[Epoch 01] dev_loss_per_frame=2.6589, dev_CER=63.43%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=63.43%)
allocated=38.6MB reserved=8082.0MB
train_loss: 2.530 train cer: 0.608
[Epoch 02] dev_loss_per_frame=2.0708, dev_CER=53.11%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=53.11%)
allocated=38.6MB reserved=8082.0MB
train_loss: 2.247 train cer: 0.558
[Epoch 03] dev_loss_per_frame=1.8656, dev_CER=48.60%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=48.60%)
allocated=39.1MB reserved=8618.0MB
train_loss: 2.088 train cer: 0.535
[Epoch 04] dev_loss_per_frame=1.7735, dev_CER=46.49%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=46.49%)
allocated=39.1MB reserved=8622.0MB
train_loss: 1.982 train cer: 0.511
[Epoch 05] dev_loss_per_frame=1.6299, dev_CER=43.20%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=43.20%)
allocated=38.6MB reserved=8622.0MB
train_loss: 1.866 train cer: 0.486
[Epoch 06] dev_loss_per_frame=1.5721, dev_CER=41.80%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=41.80%)
allocated=38.6MB reserved=8622.0MB
train_loss: 1.803 train cer: 0.464
[Epoch 07] dev_loss_per_frame=1.5091, dev_CER=40.33%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=40.33%)
allocated=39.0MB reserved=8622.0MB
train_loss: 1.740 train cer: 0.454
[Epoch 08] dev_loss_per_frame=1.5055, dev_CER=39.95%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=39.95%)
allocated=38.6MB reserved=8622.0MB
train_loss: 1.680 train cer: 0.436
[Epoch 09] dev_loss_per_frame=1.4499, dev_CER=39.01%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=39.01%)
allocated=38.6MB reserved=8622.0MB
train_loss: 1.638 train cer: 0.438
[Epoch 10] dev_loss_per_frame=1.3772, dev_CER=37.13%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=37.13%)
allocated=39.1MB reserved=8622.0MB
train_loss: 1.604 train cer: 0.431
[Epoch 11] dev_loss_per_frame=1.3747, dev_CER=37.05%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=37.05%)
allocated=38.6MB reserved=8622.0MB
train_loss: 1.558 train cer: 0.429
[Epoch 12] dev_loss_per_frame=1.3126, dev_CER=35.56%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=35.56%)
allocated=38.6MB reserved=12906.0MB
train_loss: 1.548 train cer: 0.404
[Epoch 13] dev_loss_per_frame=1.3428, dev_CER=36.11%
allocated=39.3MB reserved=9056.0MB
train_loss: 1.516 train cer: 0.406
[Epoch 14] dev_loss_per_frame=1.2883, dev_CER=34.82%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=34.82%)
allocated=38.6MB reserved=9058.0MB
train_loss: 1.475 train cer: 0.390
[Epoch 15] dev_loss_per_frame=1.3332, dev_CER=35.58%
allocated=38.6MB reserved=9058.0MB
train_loss: 1.453 train cer: 0.388
[Epoch 16] dev_loss_per_frame=1.3565, dev_CER=36.32%
allocated=38.6MB reserved=9060.0MB
train_loss: 1.440 train cer: 0.377
[Epoch 17] dev_loss_per_frame=1.2660, dev_CER=34.31%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=34.31%)
allocated=39.1MB reserved=9078.0MB
train_loss: 1.434 train cer: 0.395
[Epoch 18] dev_loss_per_frame=1.2582, dev_CER=34.05%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=34.05%)
allocated=38.7MB reserved=9078.0MB
train_loss: 1.417 train cer: 0.379
[Epoch 19] dev_loss_per_frame=1.2322, dev_CER=33.08%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=33.08%)
allocated=38.6MB reserved=9078.0MB
train_loss: 1.407 train cer: 0.383
[Epoch 20] dev_loss_per_frame=1.2291, dev_CER=33.20%
allocated=38.6MB reserved=9078.0MB
train_loss: 1.380 train cer: 0.369
[Epoch 21] dev_loss_per_frame=1.2364, dev_CER=33.14%
allocated=39.0MB reserved=9078.0MB
train_loss: 1.351 train cer: 0.369
[Epoch 22] dev_loss_per_frame=1.1955, dev_CER=32.29%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=32.29%)
allocated=38.6MB reserved=9078.0MB
train_loss: 1.358 train cer: 0.363
[Epoch 23] dev_loss_per_frame=1.1872, dev_CER=32.22%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=32.22%)
allocated=38.6MB reserved=9078.0MB
train_loss: 1.328 train cer: 0.350
[Epoch 24] dev_loss_per_frame=1.1774, dev_CER=31.84%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=31.84%)
allocated=38.6MB reserved=9078.0MB
train_loss: 1.299 train cer: 0.355
[Epoch 25] dev_loss_per_frame=1.1779, dev_CER=31.74%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=31.74%)
allocated=38.7MB reserved=9078.0MB
train_loss: 1.320 train cer: 0.359
[Epoch 26] dev_loss_per_frame=1.1702, dev_CER=31.63%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=31.63%)
allocated=38.6MB reserved=9078.0MB
train_loss: 1.289 train cer: 0.330
[Epoch 27] dev_loss_per_frame=1.1484, dev_CER=30.90%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=30.90%)
allocated=38.6MB reserved=9080.0MB
train_loss: 1.288 train cer: 0.354
[Epoch 28] dev_loss_per_frame=1.1654, dev_CER=31.29%
allocated=39.0MB reserved=9080.0MB
train_loss: 1.255 train cer: 0.338
[Epoch 29] dev_loss_per_frame=1.1588, dev_CER=30.95%
allocated=38.6MB reserved=9082.0MB
train_loss: 1.239 train cer: 0.338
[Epoch 30] dev_loss_per_frame=1.0778, dev_CER=29.05%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=29.05%)
allocated=38.6MB reserved=9082.0MB
train_loss: 1.216 train cer: 0.341
[Epoch 31] dev_loss_per_frame=1.0895, dev_CER=29.35%
allocated=38.8MB reserved=9082.0MB
train_loss: 1.208 train cer: 0.334
[Epoch 32] dev_loss_per_frame=1.0751, dev_CER=28.96%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=28.96%)
allocated=39.5MB reserved=9082.0MB
train_loss: 1.194 train cer: 0.312
[Epoch 33] dev_loss_per_frame=1.0856, dev_CER=29.32%
allocated=38.6MB reserved=9082.0MB
train_loss: 1.183 train cer: 0.315
[Epoch 34] dev_loss_per_frame=1.0725, dev_CER=28.98%
allocated=39.4MB reserved=9082.0MB
train_loss: 1.179 train cer: 0.321
[Epoch 35] dev_loss_per_frame=1.0574, dev_CER=28.50%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=28.50%)
allocated=38.6MB reserved=9082.0MB
train_loss: 1.163 train cer: 0.319
[Epoch 36] dev_loss_per_frame=1.0673, dev_CER=28.64%
allocated=39.2MB reserved=9082.0MB
train_loss: 1.167 train cer: 0.330
[Epoch 37] dev_loss_per_frame=1.0630, dev_CER=28.70%
allocated=39.5MB reserved=9082.0MB
train_loss: 1.160 train cer: 0.306
[Epoch 38] dev_loss_per_frame=1.0377, dev_CER=27.92%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=27.92%)
allocated=38.6MB reserved=9082.0MB
train_loss: 1.143 train cer: 0.295
[Epoch 39] dev_loss_per_frame=1.0392, dev_CER=27.89%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=27.89%)
allocated=38.7MB reserved=9082.0MB
train_loss: 1.145 train cer: 0.331
[Epoch 40] dev_loss_per_frame=1.0437, dev_CER=28.04%
allocated=38.6MB reserved=9082.0MB
train_loss: 1.144 train cer: 0.320
[Epoch 41] dev_loss_per_frame=1.0377, dev_CER=27.92%
allocated=38.6MB reserved=9082.0MB
train_loss: 1.126 train cer: 0.313
[Epoch 42] dev_loss_per_frame=1.0133, dev_CER=27.38%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=27.38%)
allocated=38.9MB reserved=9082.0MB
train_loss: 1.122 train cer: 0.316
[Epoch 43] dev_loss_per_frame=1.0281, dev_CER=27.65%
allocated=38.6MB reserved=9082.0MB
train_loss: 1.122 train cer: 0.306
[Epoch 44] dev_loss_per_frame=1.0203, dev_CER=27.49%
allocated=38.6MB reserved=9082.0MB
train_loss: 1.123 train cer: 0.310
[Epoch 45] dev_loss_per_frame=1.0256, dev_CER=27.55%
allocated=38.9MB reserved=9082.0MB
train_loss: 1.103 train cer: 0.311
[Epoch 46] dev_loss_per_frame=1.0011, dev_CER=26.78%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=26.78%)
allocated=38.6MB reserved=9082.0MB
train_loss: 1.100 train cer: 0.303
[Epoch 47] dev_loss_per_frame=0.9930, dev_CER=26.73%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=26.73%)
allocated=38.8MB reserved=9082.0MB
train_loss: 1.097 train cer: 0.316
[Epoch 48] dev_loss_per_frame=1.0121, dev_CER=27.13%
allocated=38.7MB reserved=9082.0MB
train_loss: 1.085 train cer: 0.309
[Epoch 49] dev_loss_per_frame=0.9901, dev_CER=26.66%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=26.66%)
allocated=39.3MB reserved=9082.0MB
train_loss: 1.088 train cer: 0.292
[Epoch 50] dev_loss_per_frame=1.0217, dev_CER=27.30%
allocated=38.9MB reserved=9082.0MB
train_loss: 1.091 train cer: 0.302
[Epoch 51] dev_loss_per_frame=0.9881, dev_CER=26.54%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=26.54%)
allocated=38.9MB reserved=9082.0MB
train_loss: 1.083 train cer: 0.294
[Epoch 52] dev_loss_per_frame=0.9888, dev_CER=26.40%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=26.40%)
allocated=39.0MB reserved=9082.0MB
train_loss: 1.082 train cer: 0.301
[Epoch 53] dev_loss_per_frame=1.0128, dev_CER=27.19%
allocated=38.6MB reserved=9082.0MB
train_loss: 1.082 train cer: 0.298
[Epoch 54] dev_loss_per_frame=1.0025, dev_CER=26.82%
allocated=38.6MB reserved=9082.0MB
train_loss: 1.064 train cer: 0.290
[Epoch 55] dev_loss_per_frame=0.9866, dev_CER=26.57%
allocated=38.6MB reserved=9082.0MB
train_loss: 1.051 train cer: 0.298
[Epoch 56] dev_loss_per_frame=0.9756, dev_CER=26.10%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=26.10%)
allocated=38.6MB reserved=9082.0MB
train_loss: 1.057 train cer: 0.292
[Epoch 57] dev_loss_per_frame=0.9685, dev_CER=25.98%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=25.98%)
allocated=38.9MB reserved=9082.0MB
train_loss: 1.051 train cer: 0.297
[Epoch 58] dev_loss_per_frame=0.9919, dev_CER=26.34%
allocated=38.6MB reserved=9082.0MB
train_loss: 1.040 train cer: 0.300
[Epoch 59] dev_loss_per_frame=0.9657, dev_CER=25.70%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=25.70%)
allocated=39.4MB reserved=9082.0MB
train_loss: 1.056 train cer: 0.310
[Epoch 60] dev_loss_per_frame=0.9617, dev_CER=25.67%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=25.67%)
allocated=38.6MB reserved=9082.0MB
train_loss: 1.037 train cer: 0.291
[Epoch 61] dev_loss_per_frame=0.9513, dev_CER=25.65%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=25.65%)
allocated=39.1MB reserved=13906.0MB
train_loss: 1.035 train cer: 0.288
[Epoch 62] dev_loss_per_frame=0.9550, dev_CER=25.47%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=25.47%)
allocated=38.9MB reserved=13906.0MB
train_loss: 1.020 train cer: 0.290
[Epoch 63] dev_loss_per_frame=0.9380, dev_CER=25.27%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=25.27%)
allocated=38.6MB reserved=13906.0MB
train_loss: 1.033 train cer: 0.279
[Epoch 64] dev_loss_per_frame=0.9598, dev_CER=25.79%
allocated=38.6MB reserved=13906.0MB
train_loss: 1.023 train cer: 0.286
[Epoch 65] dev_loss_per_frame=0.9892, dev_CER=26.37%
allocated=38.7MB reserved=13906.0MB
train_loss: 1.018 train cer: 0.277
[Epoch 66] dev_loss_per_frame=0.9420, dev_CER=25.12%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=25.12%)
allocated=39.3MB reserved=13906.0MB
train_loss: 1.019 train cer: 0.278
[Epoch 67] dev_loss_per_frame=1.0007, dev_CER=26.58%
old_lr=0.001, new_lr=0.0005
allocated=38.6MB reserved=13906.0MB
train_loss: 0.935 train cer: 0.271
[Epoch 68] dev_loss_per_frame=0.8854, dev_CER=23.64%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=23.64%)
allocated=38.6MB reserved=13910.0MB
train_loss: 0.912 train cer: 0.263
[Epoch 69] dev_loss_per_frame=0.8867, dev_CER=23.67%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.898 train cer: 0.243
[Epoch 70] dev_loss_per_frame=0.8855, dev_CER=23.58%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=23.58%)
allocated=39.2MB reserved=13910.0MB
train_loss: 0.895 train cer: 0.252
[Epoch 71] dev_loss_per_frame=0.8821, dev_CER=23.34%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=23.34%)
allocated=38.6MB reserved=13910.0MB
train_loss: 0.893 train cer: 0.251
[Epoch 72] dev_loss_per_frame=0.8765, dev_CER=23.18%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=23.18%)
allocated=38.6MB reserved=13910.0MB
train_loss: 0.891 train cer: 0.257
[Epoch 73] dev_loss_per_frame=0.8832, dev_CER=23.39%
allocated=38.7MB reserved=13910.0MB
train_loss: 0.897 train cer: 0.267
[Epoch 74] dev_loss_per_frame=0.8727, dev_CER=23.17%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=23.17%)
allocated=38.6MB reserved=13910.0MB
train_loss: 0.888 train cer: 0.251
[Epoch 75] dev_loss_per_frame=0.8885, dev_CER=23.61%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.898 train cer: 0.254
[Epoch 76] dev_loss_per_frame=0.8834, dev_CER=23.29%
allocated=38.8MB reserved=13910.0MB
train_loss: 0.887 train cer: 0.245
[Epoch 77] dev_loss_per_frame=0.8895, dev_CER=23.59%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.888 train cer: 0.249
[Epoch 78] dev_loss_per_frame=0.8877, dev_CER=23.41%
old_lr=0.0005, new_lr=0.00025
allocated=38.6MB reserved=13910.0MB
train_loss: 0.839 train cer: 0.250
[Epoch 79] dev_loss_per_frame=0.8511, dev_CER=22.47%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=22.47%)
allocated=38.8MB reserved=13910.0MB
train_loss: 0.832 train cer: 0.239
[Epoch 80] dev_loss_per_frame=0.8520, dev_CER=22.42%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=22.42%)
allocated=38.6MB reserved=13910.0MB
train_loss: 0.821 train cer: 0.248
[Epoch 81] dev_loss_per_frame=0.8451, dev_CER=22.24%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=22.24%)
allocated=38.6MB reserved=13910.0MB
train_loss: 0.824 train cer: 0.226
[Epoch 82] dev_loss_per_frame=0.8438, dev_CER=22.19%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=22.19%)
allocated=39.0MB reserved=13910.0MB
train_loss: 0.820 train cer: 0.230
[Epoch 83] dev_loss_per_frame=0.8448, dev_CER=22.11%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=22.11%)
allocated=39.4MB reserved=13910.0MB
train_loss: 0.824 train cer: 0.244
[Epoch 84] dev_loss_per_frame=0.8474, dev_CER=22.17%
allocated=39.5MB reserved=13910.0MB
train_loss: 0.812 train cer: 0.239
[Epoch 85] dev_loss_per_frame=0.8441, dev_CER=22.03%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=22.03%)
allocated=38.6MB reserved=13910.0MB
train_loss: 0.818 train cer: 0.240
[Epoch 86] dev_loss_per_frame=0.8480, dev_CER=22.10%
old_lr=0.00025, new_lr=0.000125
allocated=38.6MB reserved=13910.0MB
train_loss: 0.793 train cer: 0.233
[Epoch 87] dev_loss_per_frame=0.8307, dev_CER=21.80%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.80%)
allocated=38.6MB reserved=13910.0MB
train_loss: 0.791 train cer: 0.222
[Epoch 88] dev_loss_per_frame=0.8347, dev_CER=21.83%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.786 train cer: 0.234
[Epoch 89] dev_loss_per_frame=0.8352, dev_CER=21.79%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.79%)
allocated=38.6MB reserved=13910.0MB
train_loss: 0.786 train cer: 0.218
[Epoch 90] dev_loss_per_frame=0.8336, dev_CER=21.73%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.73%)
allocated=38.6MB reserved=13910.0MB
train_loss: 0.780 train cer: 0.219
[Epoch 91] dev_loss_per_frame=0.8315, dev_CER=21.63%
old_lr=0.000125, new_lr=6.25e-05
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.63%)
allocated=38.6MB reserved=13910.0MB
train_loss: 0.772 train cer: 0.233
[Epoch 92] dev_loss_per_frame=0.8274, dev_CER=21.57%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.57%)
allocated=38.7MB reserved=13910.0MB
train_loss: 0.771 train cer: 0.215
[Epoch 93] dev_loss_per_frame=0.8279, dev_CER=21.56%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.56%)
allocated=39.5MB reserved=13910.0MB
train_loss: 0.768 train cer: 0.215
[Epoch 94] dev_loss_per_frame=0.8282, dev_CER=21.54%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.54%)
allocated=38.8MB reserved=13910.0MB
train_loss: 0.774 train cer: 0.234
[Epoch 95] dev_loss_per_frame=0.8274, dev_CER=21.53%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.53%)
allocated=38.6MB reserved=13910.0MB
train_loss: 0.769 train cer: 0.214
[Epoch 96] dev_loss_per_frame=0.8293, dev_CER=21.58%
old_lr=6.25e-05, new_lr=3.125e-05
allocated=38.9MB reserved=13910.0MB
train_loss: 0.764 train cer: 0.230
[Epoch 97] dev_loss_per_frame=0.8243, dev_CER=21.43%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.43%)
allocated=39.0MB reserved=13910.0MB
train_loss: 0.755 train cer: 0.228
[Epoch 98] dev_loss_per_frame=0.8251, dev_CER=21.48%
allocated=39.3MB reserved=13910.0MB
train_loss: 0.759 train cer: 0.216
[Epoch 99] dev_loss_per_frame=0.8245, dev_CER=21.41%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.41%)
allocated=39.5MB reserved=13910.0MB
train_loss: 0.760 train cer: 0.217
[Epoch 100] dev_loss_per_frame=0.8245, dev_CER=21.44%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.760 train cer: 0.220
[Epoch 101] dev_loss_per_frame=0.8265, dev_CER=21.43%
old_lr=3.125e-05, new_lr=1.5625e-05
allocated=39.5MB reserved=13910.0MB
train_loss: 0.756 train cer: 0.214
[Epoch 102] dev_loss_per_frame=0.8239, dev_CER=21.36%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.36%)
allocated=38.6MB reserved=13910.0MB
train_loss: 0.760 train cer: 0.225
[Epoch 103] dev_loss_per_frame=0.8262, dev_CER=21.47%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.754 train cer: 0.219
[Epoch 104] dev_loss_per_frame=0.8246, dev_CER=21.37%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.755 train cer: 0.219
[Epoch 105] dev_loss_per_frame=0.8274, dev_CER=21.45%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.759 train cer: 0.213
[Epoch 106] dev_loss_per_frame=0.8250, dev_CER=21.37%
old_lr=1.5625e-05, new_lr=7.8125e-06
allocated=38.7MB reserved=13910.0MB
train_loss: 0.754 train cer: 0.221
[Epoch 107] dev_loss_per_frame=0.8247, dev_CER=21.40%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.753 train cer: 0.212
[Epoch 108] dev_loss_per_frame=0.8235, dev_CER=21.37%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.750 train cer: 0.227
[Epoch 109] dev_loss_per_frame=0.8247, dev_CER=21.40%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.757 train cer: 0.229
[Epoch 110] dev_loss_per_frame=0.8235, dev_CER=21.36%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.760 train cer: 0.213
[Epoch 111] dev_loss_per_frame=0.8243, dev_CER=21.39%
allocated=39.4MB reserved=13910.0MB
train_loss: 0.752 train cer: 0.215
[Epoch 112] dev_loss_per_frame=0.8249, dev_CER=21.40%
old_lr=7.8125e-06, new_lr=3.90625e-06
allocated=39.6MB reserved=13910.0MB
train_loss: 0.749 train cer: 0.218
[Epoch 113] dev_loss_per_frame=0.8241, dev_CER=21.38%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.752 train cer: 0.228
[Epoch 114] dev_loss_per_frame=0.8228, dev_CER=21.36%
allocated=38.8MB reserved=13910.0MB
train_loss: 0.753 train cer: 0.220
[Epoch 115] dev_loss_per_frame=0.8259, dev_CER=21.41%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.750 train cer: 0.219
[Epoch 116] dev_loss_per_frame=0.8246, dev_CER=21.38%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.754 train cer: 0.206
[Epoch 117] dev_loss_per_frame=0.8244, dev_CER=21.39%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.751 train cer: 0.225
[Epoch 118] dev_loss_per_frame=0.8237, dev_CER=21.39%
old_lr=3.90625e-06, new_lr=1.953125e-06
allocated=38.7MB reserved=13910.0MB
train_loss: 0.751 train cer: 0.222
[Epoch 119] dev_loss_per_frame=0.8240, dev_CER=21.40%
allocated=39.0MB reserved=13910.0MB
train_loss: 0.749 train cer: 0.216
[Epoch 120] dev_loss_per_frame=0.8238, dev_CER=21.41%
allocated=38.6MB reserved=13910.0MB
train_loss: 0.754 train cer: 0.219
[Epoch 121] dev_loss_per_frame=0.8232, dev_CER=21.36%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.36%)
allocated=39.3MB reserved=13910.0MB
train_loss: 0.749 train cer: 0.217
[Epoch 122] dev_loss_per_frame=0.8242, dev_CER=21.35%
old_lr=1.953125e-06, new_lr=9.765625e-07
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.35%)
allocated=38.6MB reserved=13912.0MB
train_loss: 0.751 train cer: 0.227
[Epoch 123] dev_loss_per_frame=0.8224, dev_CER=21.35%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.35%)
allocated=39.5MB reserved=13912.0MB
train_loss: 0.755 train cer: 0.211
[Epoch 124] dev_loss_per_frame=0.8230, dev_CER=21.36%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.750 train cer: 0.209
[Epoch 125] dev_loss_per_frame=0.8242, dev_CER=21.39%
allocated=39.4MB reserved=13912.0MB
train_loss: 0.751 train cer: 0.215
[Epoch 126] dev_loss_per_frame=0.8228, dev_CER=21.31%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251227-070231.pt (best_CER=21.31%)
allocated=38.6MB reserved=13912.0MB
train_loss: 0.749 train cer: 0.222
[Epoch 127] dev_loss_per_frame=0.8239, dev_CER=21.38%
old_lr=9.765625e-07, new_lr=4.8828125e-07
allocated=38.6MB reserved=13912.0MB
train_loss: 0.750 train cer: 0.202
[Epoch 128] dev_loss_per_frame=0.8241, dev_CER=21.38%
allocated=38.8MB reserved=13912.0MB
train_loss: 0.756 train cer: 0.217
[Epoch 129] dev_loss_per_frame=0.8221, dev_CER=21.33%
allocated=39.3MB reserved=13912.0MB
train_loss: 0.752 train cer: 0.216
[Epoch 130] dev_loss_per_frame=0.8217, dev_CER=21.34%
allocated=39.1MB reserved=13912.0MB
train_loss: 0.752 train cer: 0.216
[Epoch 131] dev_loss_per_frame=0.8230, dev_CER=21.34%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.752 train cer: 0.220
[Epoch 132] dev_loss_per_frame=0.8249, dev_CER=21.40%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.755 train cer: 0.230
[Epoch 133] dev_loss_per_frame=0.8221, dev_CER=21.34%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.747 train cer: 0.206
[Epoch 134] dev_loss_per_frame=0.8225, dev_CER=21.39%
old_lr=4.8828125e-07, new_lr=2.44140625e-07
allocated=38.6MB reserved=13912.0MB
train_loss: 0.758 train cer: 0.221
[Epoch 135] dev_loss_per_frame=0.8230, dev_CER=21.34%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.753 train cer: 0.220
[Epoch 136] dev_loss_per_frame=0.8246, dev_CER=21.37%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.752 train cer: 0.215
[Epoch 137] dev_loss_per_frame=0.8232, dev_CER=21.36%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.746 train cer: 0.230
[Epoch 138] dev_loss_per_frame=0.8235, dev_CER=21.34%
old_lr=2.44140625e-07, new_lr=1.220703125e-07
allocated=38.6MB reserved=13912.0MB
train_loss: 0.748 train cer: 0.211
[Epoch 139] dev_loss_per_frame=0.8232, dev_CER=21.34%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.752 train cer: 0.218
[Epoch 140] dev_loss_per_frame=0.8225, dev_CER=21.35%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.751 train cer: 0.213
[Epoch 141] dev_loss_per_frame=0.8220, dev_CER=21.34%
allocated=39.0MB reserved=13912.0MB
train_loss: 0.748 train cer: 0.206
[Epoch 142] dev_loss_per_frame=0.8243, dev_CER=21.35%
old_lr=1.220703125e-07, new_lr=6.103515625e-08
allocated=39.3MB reserved=13912.0MB
train_loss: 0.751 train cer: 0.217
[Epoch 143] dev_loss_per_frame=0.8249, dev_CER=21.40%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.753 train cer: 0.219
[Epoch 144] dev_loss_per_frame=0.8229, dev_CER=21.37%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.752 train cer: 0.212
[Epoch 145] dev_loss_per_frame=0.8241, dev_CER=21.37%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.743 train cer: 0.212
[Epoch 146] dev_loss_per_frame=0.8239, dev_CER=21.39%
old_lr=6.103515625e-08, new_lr=3.0517578125e-08
allocated=38.6MB reserved=13912.0MB
train_loss: 0.752 train cer: 0.208
[Epoch 147] dev_loss_per_frame=0.8226, dev_CER=21.38%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.751 train cer: 0.202
[Epoch 148] dev_loss_per_frame=0.8244, dev_CER=21.36%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.753 train cer: 0.221
[Epoch 149] dev_loss_per_frame=0.8223, dev_CER=21.34%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.747 train cer: 0.214
[Epoch 150] dev_loss_per_frame=0.8230, dev_CER=21.38%
old_lr=3.0517578125e-08, new_lr=1.52587890625e-08
allocated=38.6MB reserved=13912.0MB
train_loss: 0.752 train cer: 0.220
[Epoch 151] dev_loss_per_frame=0.8226, dev_CER=21.35%
allocated=38.6MB reserved=13912.0MB
train_loss: 0.751 train cer: 0.219
[Epoch 152] dev_loss_per_frame=0.8238, dev_CER=21.40%
allocated=39.3MB reserved=13912.0MB
train_loss: 0.753 train cer: 0.221
[Epoch 153] dev_loss_per_frame=0.8230, dev_CER=21.37%
allocated=38.6MB reserved=13912.0MB
