===== SCRIPT SNAPSHOT BEGIN =====
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2025/11/22
# @Author  : Joyful Buffalo
# @File    : simple_ctc_asr.py
# !/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import annotations

import json
import math
import random
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Tuple, Optional, Iterator, cast

import numpy as np
import torch
import torchaudio
from torch import nn
from torch.nn import functional as F
from torch.nn.attention import sdpa_kernel, SDPBackend
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import Dataset, DataLoader, Sampler
from torchaudio.compliance import kaldi
from tqdm import tqdm
from utils.specAug import SpecAugment


@dataclass
class ASRConfig:
    train_manifest: str
    dev_manifest: str
    sample_rate: int = 16000
    num_mel_bins: int = 80
    frame_length_ms: float = 25.0
    frame_shift_ms: float = 10.0
    dither: float = 0.0
    hidden_size: int = 512
    layers: int = 4
    dropout: float = 0.1
    batch_size: Optional[int] = None
    max_frames_per_batch: Optional[int] = 8192
    num_epochs: int = 10
    learning_rate: float = 1e-3
    weight_decay: float = 1e-5
    max_grad_norm: float = 5.0
    num_workers: int = 4
    prefetch_factor: int = 1
    bucket_size: int = 100
    pin_memory: bool = True
    shuffle: bool = True


# ======================
# 动态batch采样器
# ======================
class LengthBucketBatchSampler(Sampler[List[int]]):
    """按长度分桶的动态batch采样器，支持固定batch_size或max_frames_per_batch"""

    def __init__(
            self,
            lengths: List[int],
            batch_size: Optional[int] = None,
            max_frames_per_batch: Optional[int] = None,
            shuffle: bool = True,
            bucket_size: int = 100,
    ):
        super(LengthBucketBatchSampler, self).__init__(None)
        assert (batch_size is None) ^ (max_frames_per_batch is None), \
            "Exactly one of batch_size or max_frames_per_batch should be provided."
        self.lengths = lengths
        self.batch_size = batch_size
        self.max_frames_per_batch = max_frames_per_batch
        self.shuffle = shuffle
        self.bucket_size = bucket_size
        self._indices = list(range(len(lengths)))
        self.g = torch.Generator().manual_seed(torch.seed())

    def __iter__(self) -> Iterator[List[int]]:
        # 返回 batch indices
        if self.shuffle:
            indices = [self._indices[i] for i in torch.randperm(len(self._indices), generator=self.g).tolist()]
        else:
            indices = self._indices

        # 分桶 + 桶内按长度升序
        buckets = [
            indices[i:i + self.bucket_size]
            for i in range(0, len(indices), self.bucket_size)
        ]
        for b in buckets:
            b.sort(key=lambda i: self.lengths[i])

        flat = [i for b in buckets for i in b]

        if self.batch_size is not None:
            for i in range(0, len(flat), self.batch_size):
                yield flat[i:i + self.batch_size]
        else:
            current, cur_frames = [], 0
            for i in flat:
                length = int(self.lengths[i])
                if len(current) > 0 and (cur_frames + length) > int(self.max_frames_per_batch):
                    yield current
                    current, cur_frames = [], 0
                current.append(i)
                cur_frames += length
            if len(current) > 0:
                yield current

    def __len__(self) -> int:
        if self.batch_size is not None:
            return math.ceil(len(self.lengths) / self.batch_size)
        # max_frames 模式下，__len__ 很难精确；给出近似上界
        avg = (sum(self.lengths) / max(1, len(self.lengths)))
        return max(1, int(sum(self.lengths) / max(self.max_frames_per_batch, cast(int, avg))))


# ======================
# 字级 tokenizer（0 留给 CTC blank）
# ======================
class CharTokenizer:
    """最简单的“字级”分词器，0 号留给 CTC blank。"""

    def __init__(self, char2id: Dict[str, int]) -> None:
        self.blank_id: int = 0
        self.char2id: Dict[str, int] = char2id
        # id2char 索引 0 为 <blank>，其余按 id 排序
        self.id2char: List[str] = ["<blank>"] + [
            ch for ch, _ in sorted(char2id.items(), key=lambda x: x[1])
        ]

    @classmethod
    def build_from_jsonl(cls, manifest_path: str) -> "CharTokenizer":
        chars: set[str] = set()
        path = Path(manifest_path)
        with path.open("r", encoding="utf-8") as f:
            for line in f:
                if not line.strip():
                    continue
                item = json.loads(line)
                # 支持 txt 或 text 两种字段名
                txt = item.get("txt") or item.get("text")
                if txt is None:
                    raise ValueError("每行 json 需要包含 'txt' 或 'text' 字段")
                for ch in txt:
                    if ch.isspace():
                        continue  # 去掉空格
                    chars.add(ch)
        # 按字典序排序，id 从 1 开始分配，0 保留给 blank
        char2id: Dict[str, int] = {}
        next_id = 1
        for ch in sorted(chars):
            char2id[ch] = next_id
            next_id += 1
        return cls(char2id)

    @property
    def vocab_size(self) -> int:
        # 包含 blank
        return 1 + len(self.char2id)

    def encode(self, text: str) -> List[int]:
        ids: List[int] = []
        for ch in text:
            if ch.isspace():
                continue
            idx = self.char2id.get(ch)
            if idx is None:
                # 简单处理：丢弃未登录字（也可以映射到 <unk>，这里先偷懒）
                continue
            ids.append(idx)
        return ids

    def decode_ids(self, ids: List[int]) -> str:
        chars: List[str] = []
        for idx in ids:
            if idx == self.blank_id:
                continue
            if 0 <= idx < len(self.id2char):
                ch = self.id2char[idx]
                if ch not in ("<blank>", "<unk>"):
                    chars.append(ch)
        return "".join(chars)


class JsonlASRDataset(Dataset):
    """读取 jsonl 格式清单：{"key":..., "wav":..., "txt":...} 或 {"key":..., "feat":..., "txt":..., "feat_frames":...}"""

    def __init__(self, manifest_path: str, tokenizer: CharTokenizer, config: ASRConfig,
                 compute_lengths: bool = False, use_precomputed_fbank: bool = False) -> None:
        super().__init__()
        self.manifest_path = Path(manifest_path)
        self.tokenizer = tokenizer
        self.sample_rate = config.sample_rate
        self.num_mel_bins = config.num_mel_bins
        self.frame_length_ms = config.frame_length_ms
        self.frame_shift_ms = config.frame_shift_ms
        self.dither = config.dither
        self.compute_lengths = compute_lengths
        self.use_precomputed_fbank = use_precomputed_fbank
        # self.aug = SpecAugment(
        #     freq_mask_param=10,
        #     num_freq_masks=2,
        #     time_mask_param=50,
        #     num_time_masks=2,
        #     protect_last=False,
        # )

        self.entries: List[Dict[str, Any]] = []
        self.lengths: List[int] = []

        with self.manifest_path.open("r", encoding="utf-8") as f:
            for line in f:
                if not line.strip():
                    continue
                item = json.loads(line)
                txt = item.get("txt") or item.get("text")
                if txt is None:
                    raise ValueError("清单每行必须包含 'txt'/'text'")

                # 判断是使用预处理的fbank还是原始wav
                if use_precomputed_fbank:
                    feat = item.get("feat")
                    # if random.random()< 0.5:
                    #     feat = self.aug(feat)
                    if feat is None:
                        raise ValueError("使用预处理fbank时，清单每行必须包含 'feat'")
                    self.entries.append({"feat": feat, "txt": txt})

                    # 如果需要计算长度（用于动态batch）
                    if compute_lengths:
                        feat_frames = item.get("feat_frames", 0)
                        if feat_frames > 0:
                            self.lengths.append(feat_frames)
                        else:
                            print(f"警告: {feat} 没有帧数信息，使用默认值")
                            self.lengths.append(100)
                else:
                    wav = item.get("wav")
                    if wav is None:
                        raise ValueError("清单每行必须包含 'wav'")
                    self.entries.append({"wav": wav, "txt": txt})

                    # 如果需要计算长度（用于动态batch）
                    if compute_lengths:
                        # 从JSON中读取时长（秒），计算特征帧数
                        duration_sec = item.get("length", 0.0)
                        if duration_sec > 0:
                            duration_ms = duration_sec * 1000
                            feat_frames = int((duration_ms - self.frame_length_ms) / self.frame_shift_ms) + 1
                            self.lengths.append(max(1, feat_frames))
                        else:
                            # 如果没有时长信息，给一个默认值
                            print(f"警告: {wav} 没有时长信息，使用默认值")
                            self.lengths.append(100)

        if not self.entries:
            raise RuntimeError(f"{self.manifest_path} 为空")

    def __len__(self) -> int:
        return len(self.entries)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, str]:
        item = self.entries[idx]
        text: str = item["txt"]

        if self.use_precomputed_fbank:
            # 使用预处理好的fbank特征
            feat_path = item["feat"]
            # 使用 numpy 加载更快（特别是在 WSL2 中）
            if feat_path.endswith('.npy'):
                feat = torch.from_numpy(np.load(feat_path))
            else:
                # 兼容 .pt 格式，使用 weights_only 更快更安全
                feat = torch.load(feat_path, weights_only=False)  # (frames, num_mel_bins)
        else:
            # 实时计算fbank特征
            wav_path = item["wav"]
            waveform, sr = torchaudio.load(wav_path)  # (channels, num_samples)
            if waveform.size(0) > 1:
                waveform = waveform.mean(dim=0, keepdim=True)

            if sr != self.sample_rate:
                resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.sample_rate)
                waveform = resampler(waveform)
                sr = self.sample_rate

            # 4) 与 Kaldi 一致，将 [-1, 1] 量化到 16bit 整数范围
            #    这个写法直接参考 WeNet 官方的 compute_fbank 实现:contentReference[oaicite:5]{index=5}
            waveform = waveform * (1 << 15)

            # 5) 计算 fbank（API 见 torchaudio.compliance.kaldi.fbank 官方文档:contentReference[oaicite:6]{index=6}）
            feat = kaldi.fbank(
                waveform,
                num_mel_bins=self.num_mel_bins,
                frame_length=self.frame_length_ms,
                frame_shift=self.frame_shift_ms,
                dither=self.dither,
                energy_floor=0.0,
                sample_frequency=float(sr),
            )  # (frames, num_mel_bins)

        # 文本转为 id 序列
        target_ids = torch.tensor(self.tokenizer.encode(text), dtype=torch.long)
        return feat, target_ids, text


def asr_collate_fn(
        batch: List[Tuple[torch.Tensor, torch.Tensor, str]]
) -> Dict[str, Any]:
    feats, targets, texts = zip(*batch)

    # 对 fbank 按时间维做 padding
    feat_lengths = torch.tensor([f.size(0) for f in feats], dtype=torch.long)
    padded_feats = pad_sequence(feats, batch_first=True)  # (B, T_max, D)

    # 标签拼接成一维向量 + 长度
    target_lengths = torch.tensor([t.size(0) for t in targets], dtype=torch.long)
    concatenated_targets = torch.cat(targets, dim=0)  # (sum_target,)

    return {
        "feats": padded_feats,
        "feat_lengths": feat_lengths,
        "max_feat_lengths": feat_lengths.max().item(),
        "targets": concatenated_targets,
        "target_lengths": target_lengths,
        "texts": list(texts),
    }


class CTCConformer(nn.Module):
    def __init__(
            self,
            input_dim: int,
            vocab_size: int,
            hidden_size: int = 512,
            num_layers: int = 6,
            dropout: float = 0.1,
    ) -> None:
        super().__init__()
        self.input_proj = nn.Linear(input_dim, input_dim * 2)
        self.conformer = torchaudio.models.Conformer(
            input_dim=input_dim * 2,
            num_layers=num_layers,
            ffn_dim=hidden_size,
            dropout=dropout,
            depthwise_conv_kernel_size=15,
            num_heads=8
        )
        self.fc = nn.Linear(input_dim * 2, vocab_size)

    def forward(self, feats: torch.Tensor, feat_lengths, max_length) -> torch.Tensor:
        feats = self.input_proj(feats)
        x, _ = self.conformer(feats, feat_lengths)  # (B, T, 2H)
        logits = self.fc(x)  # (B, T, V)
        return logits


def ctc_greedy_decode(
        logit_batch: torch.Tensor,
        feat_lengths: torch.Tensor,
        blank_id: int,
) -> List[List[int]]:
    """
    最简单 CTC 贪心解码：按时间取 argmax，然后压缩重复 & 去掉 blank。
    logit_batch: (B, T, V)
    feat_lengths: (B,)
    """
    with torch.no_grad():
        probs = F.log_softmax(logit_batch, dim=-1)
        pred_ids = torch.argmax(probs, dim=-1)  # (B, T)

    results: List[List[int]] = []
    for b in range(pred_ids.size(0)):
        length = int(feat_lengths[b].item())
        seq = pred_ids[b, :length].tolist()
        collapsed: List[int] = []
        prev = blank_id
        for idx in seq:
            if idx != blank_id and idx != prev:
                collapsed.append(idx)
            prev = idx
        results.append(collapsed)
    return results


def char_edit_distance(ref: str, hyp: str) -> int:
    """标准 Levenshtein 编辑距离（以“字”为单位）"""
    ref_chars = list(ref)
    hyp_chars = list(hyp)
    n = len(ref_chars)
    m = len(hyp_chars)
    if n == 0:
        return m
    if m == 0:
        return n
    # DP 矩阵大小 (n+1) x (m+1)
    dp = [[0] * (m + 1) for _ in range(n + 1)]
    for i in range(n + 1):
        dp[i][0] = i
    for j in range(m + 1):
        dp[0][j] = j
    for i in range(1, n + 1):
        for j in range(1, m + 1):
            cost = 0 if ref_chars[i - 1] == hyp_chars[j - 1] else 1
            dp[i][j] = min(
                dp[i - 1][j] + 1,  # 删除
                dp[i][j - 1] + 1,  # 插入
                dp[i - 1][j - 1] + cost,  # 替换
            )
    return dp[n][m]


def evaluate_cer(
        model: nn.Module,
        dataloader: DataLoader,
        tokenizer: CharTokenizer,
        device: torch.device,
        ctc_loss: nn.CTCLoss,
) -> tuple[float, float]:
    model.eval()
    total_edit = 0
    total_chars = 0
    total_loss = 0
    total_frame = 0
    with torch.no_grad():
        for batch in tqdm(dataloader, ncols=100):
            feats = batch["feats"].to(device)
            feat_lengths = batch["feat_lengths"].to(device)
            texts = batch["texts"]
            targets = batch["targets"].to(device, non_blocking=True)
            max_length = batch["max_feat_lengths"]
            target_lengths = batch["target_lengths"].to(device, non_blocking=True)
            logits = model(feats, feat_lengths, max_length)  # (B, T, V)
            log_probs = F.log_softmax(logits, dim=-1).transpose(0, 1)
            loss = ctc_loss(log_probs, targets, feat_lengths, target_lengths)
            pred_id_seqs = ctc_greedy_decode(logits, feat_lengths, tokenizer.blank_id)
            batch_frame = int(feat_lengths.sum().item())
            total_loss += loss.item() * batch_frame
            total_frame += batch_frame
            for ref_text, pred_ids in zip(texts, pred_id_seqs):
                hyp_text = tokenizer.decode_ids(pred_ids)
                # 这里也去掉 ref 中的空白字符
                ref = "".join(ch for ch in ref_text if not ch.isspace())
                edit = char_edit_distance(ref, hyp_text)
                total_edit += edit
                total_chars += len(ref)
    if total_chars == 0:
        return 0.0, 0.
    return total_edit / total_chars, total_loss / total_frame


aug = SpecAugment(
    freq_mask_param=10,  # F = 10
    num_freq_masks=2,  # mF = 2
    time_mask_param=50,  # T = 50（帧）
    num_time_masks=2,  # mT = 2
    protect_last=False,
)


def train_one_epoch(
        model: nn.Module,
        dataloader: DataLoader,
        optimizer: torch.optim.Optimizer,
        ctc_loss: nn.CTCLoss,
        device: torch.device,
        max_grad_norm: float,
        tokenizer: CharTokenizer,
) -> float:
    model.train()
    total_loss = 0.0
    total_frames = 0
    total_edit = 0
    total_chars = 0
    idx = 0
    for batch in tqdm(dataloader, ncols=100, position=1):
        feats = batch["feats"].to(device, non_blocking=True)
        feat_lengths = batch["feat_lengths"].to(device, non_blocking=True)
        targets = batch["targets"].to(device, non_blocking=True)
        target_lengths = batch["target_lengths"].to(device, non_blocking=True)
        max_length = batch["max_feat_lengths"]
        if random.random() < 0.1:
            feats = aug(feats)

        optimizer.zero_grad(set_to_none=True)
        with torch.autocast(device_type='cuda', dtype=torch.bfloat16):
            logits = model(feats, feat_lengths, max_length)  # (B, T, V)
            # CTCLoss 官方文档要求 log_probs 形状为 (T, N, C):contentReference[oaicite:7]{index=7}
            log_probs = F.log_softmax(logits, dim=-1).transpose(0, 1)

        loss = ctc_loss(log_probs, targets, feat_lengths, target_lengths)
        loss.backward()
        if max_grad_norm > 0.0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
        optimizer.step()

        batch_frames = int(feat_lengths.sum().item())
        total_loss += loss.item() * batch_frames
        total_frames += batch_frames
        if idx % 100 == 0:
            with torch.no_grad():
                pred_id_seqs = ctc_greedy_decode(logits, feat_lengths, tokenizer.blank_id)
                offset = 0
                for b, pred_ids in enumerate(pred_id_seqs):
                    cur_len = int(target_lengths[b].item())
                    tgt_ids = targets[offset:offset + cur_len].tolist()
                    offset += cur_len
                    ref_text = tokenizer.decode_ids(tgt_ids)
                    hyp_text = tokenizer.decode_ids(pred_ids)
                    edit = char_edit_distance(ref_text, hyp_text)
                    total_edit += edit
                    total_chars += len(ref_text)
        idx += 1
    print(f'train_loss: {total_loss / total_frames:.3f} train cer: {total_edit / total_chars:.3f}')
    if total_frames == 0:
        return 0.0
    return total_loss / total_frames


def dynamic_pre_compile(train_loader, device, model, max_T):
    warmup_batch = next(iter(train_loader))
    warmup_feats = warmup_batch["feats"].to(device)  # (B, T, D)
    warmup_feat_lengths = warmup_batch["feat_lengths"].to(device)
    warmup_max_len = int(warmup_feat_lengths.max().item())

    torch._dynamo.mark_dynamic(warmup_feats, 1, min=1, max=int(max_T))
    model = torch.compile(model)
    with torch.no_grad():
        _ = model(warmup_feats, warmup_feat_lengths, warmup_max_len)
    return model


def main() -> None:
    import time, sys, atexit
    run_dir = Path("logs") / time.strftime("%Y%m%d-%H%M%S")
    run_dir.mkdir(parents=True, exist_ok=True)
    log_f = open(run_dir / "stdout.log", "w", encoding="utf-8", buffering=1)
    try:
        src = Path(__file__).read_text(encoding="utf-8")
    except Exception as e:
        src = f"<FAILED TO READ __file__: {e}>"
    print("===== SCRIPT SNAPSHOT BEGIN =====", file=log_f)
    print(src, file=log_f)
    print("===== SCRIPT SNAPSHOT END =====", file=log_f)
    log_f.flush()
    class _Tee:
        def __init__(self, *fs): self.fs = fs
        def write(self, s):
            for f in self.fs:
                f.write(s); f.flush()
        def flush(self):
            for f in self.fs:
                f.flush()
    sys.stdout = _Tee(sys.__stdout__, log_f)
    atexit.register(log_f.close)
    print(f"[log] run_dir={run_dir.resolve()}")

    torch.set_float32_matmul_precision('high')
    config = ASRConfig(
        train_manifest="dataset/train_fbank_relpath.jsonl",
        dev_manifest="dataset/dev_fbank_relpath.jsonl",
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("使用设备:", device)

    # === 1. 根据训练集构建"字级"词表 ===
    print("构建字级词表...")
    tokenizer = CharTokenizer.build_from_jsonl(config.train_manifest)
    print("vocab_size (含 blank):", tokenizer.vocab_size)

    # === 2. 构建 Dataset / DataLoader ===
    print("构建数据集...")
    train_dataset = JsonlASRDataset(config.train_manifest, tokenizer, config, compute_lengths=True, use_precomputed_fbank=True)
    dev_dataset = JsonlASRDataset(config.dev_manifest, tokenizer, config, compute_lengths=True, use_precomputed_fbank=True)

    # 创建动态batch采样器
    print("创建动态batch采样器...")
    train_sampler = LengthBucketBatchSampler(
        lengths=train_dataset.lengths,
        batch_size=config.batch_size,
        max_frames_per_batch=config.max_frames_per_batch,
        shuffle=config.shuffle,
        bucket_size=config.bucket_size,
    )
    dev_sampler = LengthBucketBatchSampler(
        lengths=dev_dataset.lengths,
        batch_size=config.batch_size,
        max_frames_per_batch=config.max_frames_per_batch,
        shuffle=False,
        bucket_size=config.bucket_size,
    )

    train_loader = DataLoader(
        train_dataset,
        batch_sampler=train_sampler,
        num_workers=config.num_workers,
        pin_memory=config.pin_memory,
        collate_fn=asr_collate_fn,
        prefetch_factor=config.prefetch_factor,
    )
    dev_loader = DataLoader(
        dev_dataset,
        batch_sampler=dev_sampler,
        num_workers=config.num_workers,
        pin_memory=config.pin_memory,
        collate_fn=asr_collate_fn,
        prefetch_factor=config.prefetch_factor,
    )
    # === 3. 构建模型 / 损失 / 优化器 ===
    input_dim = config.num_mel_bins
    vocab_size = tokenizer.vocab_size
    model = CTCConformer(
        input_dim=input_dim,
        vocab_size=vocab_size,
        hidden_size=config.hidden_size,
        num_layers=config.layers,
        dropout=config.dropout,
    ).to(device)

    ctc_loss = nn.CTCLoss(
        blank=tokenizer.blank_id,
        reduction="mean",
        zero_infinity=True,
    )
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.learning_rate,
        weight_decay=config.weight_decay,
        fused=True
    )
    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer,
        mode="min",
        patience=6,
        factor=0.5,
    )
    best_cer = 1.0
    best_path = Path(f"saved_models/best_ctc_asr_cer_{time.strftime("%Y%m%d-%H%M%S")}.pt")

    epoch = 1

    max_T = max(train_dataset.lengths) if train_dataset.lengths else 2048
    model = dynamic_pre_compile(train_loader, device, model, max_T=max_T)
    with sdpa_kernel(SDPBackend.MATH):
        while True:
            train_loss = train_one_epoch(
                model,
                train_loader,
                optimizer,
                ctc_loss,
                device,
                config.max_grad_norm,
                tokenizer
            )
            cer, loss = evaluate_cer(model, dev_loader, tokenizer, device, ctc_loss)
            print(
                f"[Epoch {epoch:02d}] dev_loss_per_frame={loss:.4f}, "
                f"dev_CER={cer * 100:.2f}%"
            )
            old_lr = optimizer.param_groups[0]["lr"]
            lr_scheduler.step(loss)
            new_lr = optimizer.param_groups[0]["lr"]
            if new_lr < old_lr:
                print(f'old_lr={old_lr}, new_lr={new_lr}')
            if cer < best_cer:
                best_cer = cer
                torch.save(
                    {
                        "model_state_dict": model.state_dict(),
                        "config": config.__dict__,
                        "char2id": tokenizer.char2id,
                        "blank_id": tokenizer.blank_id,
                    },
                    best_path,
                )
                print(f"  CER 改善，已保存到 {best_path} (best_CER={best_cer * 100:.2f}%)")
            # torch.cuda.empty_cache()
            alloc = torch.cuda.memory_allocated() / 1024**2
            resv  = torch.cuda.memory_reserved()  / 1024**2
            print(f"allocated={alloc:.1f}MB reserved={resv:.1f}MB")

            epoch += 1


if __name__ == "__main__":
    main()

===== SCRIPT SNAPSHOT END =====
[log] run_dir=/home/lhc/data/gudsen/asr/logs/20251220-173952
使用设备: cuda
构建字级词表...
vocab_size (含 blank): 4231
构建数据集...
创建动态batch采样器...
train_loss: 5.188 train cer: 1.205
[Epoch 01] dev_loss_per_frame=3.1238, dev_CER=70.96%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=70.96%)
allocated=60.1MB reserved=11678.0MB
train_loss: 3.126 train cer: 0.702
[Epoch 02] dev_loss_per_frame=2.6581, dev_CER=63.05%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=63.05%)
allocated=60.0MB reserved=11700.0MB
train_loss: 2.642 train cer: 0.630
[Epoch 03] dev_loss_per_frame=2.1491, dev_CER=54.08%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=54.08%)
allocated=60.1MB reserved=13746.0MB
train_loss: 2.403 train cer: 0.593
[Epoch 04] dev_loss_per_frame=1.9013, dev_CER=48.74%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=48.74%)
allocated=59.8MB reserved=13772.0MB
train_loss: 2.193 train cer: 0.548
[Epoch 05] dev_loss_per_frame=1.8282, dev_CER=47.25%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=47.25%)
allocated=59.8MB reserved=13772.0MB
train_loss: 1.987 train cer: 0.503
[Epoch 06] dev_loss_per_frame=1.5782, dev_CER=41.55%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=41.55%)
allocated=59.9MB reserved=13784.0MB
train_loss: 1.836 train cer: 0.460
[Epoch 07] dev_loss_per_frame=1.5382, dev_CER=40.32%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=40.32%)
allocated=59.8MB reserved=13784.0MB
train_loss: 1.737 train cer: 0.452
[Epoch 08] dev_loss_per_frame=1.4355, dev_CER=37.93%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=37.93%)
allocated=60.0MB reserved=13784.0MB
train_loss: 1.643 train cer: 0.432
[Epoch 09] dev_loss_per_frame=1.3255, dev_CER=35.26%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=35.26%)
allocated=59.8MB reserved=13784.0MB
train_loss: 1.581 train cer: 0.401
[Epoch 10] dev_loss_per_frame=1.3106, dev_CER=34.74%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=34.74%)
allocated=60.6MB reserved=13784.0MB
train_loss: 1.552 train cer: 0.412
[Epoch 11] dev_loss_per_frame=1.2924, dev_CER=34.36%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=34.36%)
allocated=59.8MB reserved=13784.0MB
train_loss: 1.494 train cer: 0.394
[Epoch 12] dev_loss_per_frame=1.2562, dev_CER=33.31%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=33.31%)
allocated=59.8MB reserved=13784.0MB
train_loss: 1.478 train cer: 0.376
[Epoch 13] dev_loss_per_frame=1.2131, dev_CER=32.37%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=32.37%)
allocated=59.8MB reserved=13784.0MB
train_loss: 1.407 train cer: 0.392
[Epoch 14] dev_loss_per_frame=1.1386, dev_CER=30.41%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=30.41%)
allocated=60.0MB reserved=13784.0MB
train_loss: 1.371 train cer: 0.355
[Epoch 15] dev_loss_per_frame=1.1158, dev_CER=29.56%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=29.56%)
allocated=59.9MB reserved=13784.0MB
train_loss: 1.326 train cer: 0.340
[Epoch 16] dev_loss_per_frame=1.0825, dev_CER=28.98%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=28.98%)
allocated=59.8MB reserved=13788.0MB
train_loss: 1.312 train cer: 0.343
[Epoch 17] dev_loss_per_frame=1.1186, dev_CER=29.67%
allocated=60.0MB reserved=13788.0MB
train_loss: 1.288 train cer: 0.347
[Epoch 18] dev_loss_per_frame=1.0806, dev_CER=28.68%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=28.68%)
allocated=59.8MB reserved=13788.0MB
train_loss: 1.228 train cer: 0.322
[Epoch 19] dev_loss_per_frame=1.0528, dev_CER=28.02%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=28.02%)
allocated=59.9MB reserved=13788.0MB
train_loss: 1.244 train cer: 0.344
[Epoch 20] dev_loss_per_frame=1.0525, dev_CER=28.08%
allocated=59.8MB reserved=13788.0MB
train_loss: 1.208 train cer: 0.325
[Epoch 21] dev_loss_per_frame=1.0268, dev_CER=27.32%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=27.32%)
allocated=59.9MB reserved=13788.0MB
train_loss: 1.176 train cer: 0.316
[Epoch 22] dev_loss_per_frame=0.9948, dev_CER=26.32%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=26.32%)
allocated=59.8MB reserved=13788.0MB
train_loss: 1.163 train cer: 0.309
[Epoch 23] dev_loss_per_frame=1.0042, dev_CER=26.84%
allocated=59.8MB reserved=13788.0MB
train_loss: 1.154 train cer: 0.300
[Epoch 24] dev_loss_per_frame=0.9776, dev_CER=25.89%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=25.89%)
allocated=59.8MB reserved=13788.0MB
train_loss: 1.114 train cer: 0.302
[Epoch 25] dev_loss_per_frame=0.9586, dev_CER=25.33%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=25.33%)
allocated=60.4MB reserved=13788.0MB
train_loss: 1.106 train cer: 0.307
[Epoch 26] dev_loss_per_frame=0.9495, dev_CER=25.15%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=25.15%)
allocated=59.8MB reserved=13788.0MB
train_loss: 1.071 train cer: 0.287
[Epoch 27] dev_loss_per_frame=0.9374, dev_CER=24.80%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=24.80%)
allocated=60.1MB reserved=13788.0MB
train_loss: 1.091 train cer: 0.312
[Epoch 28] dev_loss_per_frame=0.9197, dev_CER=24.25%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=24.25%)
allocated=59.9MB reserved=13788.0MB
train_loss: 1.070 train cer: 0.285
[Epoch 29] dev_loss_per_frame=0.9281, dev_CER=24.64%
allocated=60.7MB reserved=13788.0MB
train_loss: 1.059 train cer: 0.283
[Epoch 30] dev_loss_per_frame=0.9326, dev_CER=24.39%
allocated=60.1MB reserved=13788.0MB
train_loss: 1.036 train cer: 0.270
[Epoch 31] dev_loss_per_frame=0.8892, dev_CER=23.48%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=23.48%)
allocated=59.8MB reserved=13788.0MB
train_loss: 1.028 train cer: 0.292
[Epoch 32] dev_loss_per_frame=0.9888, dev_CER=26.08%
allocated=59.8MB reserved=13788.0MB
train_loss: 1.029 train cer: 0.297
[Epoch 33] dev_loss_per_frame=0.8709, dev_CER=22.96%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=22.96%)
allocated=59.9MB reserved=13788.0MB
train_loss: 0.991 train cer: 0.280
[Epoch 34] dev_loss_per_frame=0.9003, dev_CER=23.76%
allocated=60.0MB reserved=13788.0MB
train_loss: 0.974 train cer: 0.278
[Epoch 35] dev_loss_per_frame=0.8551, dev_CER=22.61%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=22.61%)
allocated=60.1MB reserved=13788.0MB
train_loss: 0.969 train cer: 0.273
[Epoch 36] dev_loss_per_frame=0.8626, dev_CER=22.71%
allocated=60.6MB reserved=13788.0MB
train_loss: 0.965 train cer: 0.275
[Epoch 37] dev_loss_per_frame=0.8650, dev_CER=22.56%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=22.56%)
allocated=59.8MB reserved=13788.0MB
train_loss: 0.947 train cer: 0.262
[Epoch 38] dev_loss_per_frame=0.8648, dev_CER=22.80%
allocated=59.8MB reserved=13788.0MB
train_loss: 0.921 train cer: 0.251
[Epoch 39] dev_loss_per_frame=0.8676, dev_CER=22.64%
allocated=59.8MB reserved=13788.0MB
train_loss: 0.945 train cer: 0.254
[Epoch 40] dev_loss_per_frame=0.8368, dev_CER=21.95%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=21.95%)
allocated=59.8MB reserved=13788.0MB
train_loss: 0.949 train cer: 0.251
[Epoch 41] dev_loss_per_frame=0.8820, dev_CER=22.96%
allocated=59.8MB reserved=13788.0MB
train_loss: 0.946 train cer: 0.262
[Epoch 42] dev_loss_per_frame=0.8783, dev_CER=22.95%
allocated=59.8MB reserved=13788.0MB
train_loss: 0.926 train cer: 0.254
[Epoch 43] dev_loss_per_frame=0.8190, dev_CER=21.43%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=21.43%)
allocated=59.8MB reserved=13796.0MB
train_loss: 0.914 train cer: 0.256
[Epoch 44] dev_loss_per_frame=0.8214, dev_CER=21.66%
allocated=59.8MB reserved=13796.0MB
train_loss: 0.906 train cer: 0.244
[Epoch 45] dev_loss_per_frame=0.8110, dev_CER=21.30%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=21.30%)
allocated=60.6MB reserved=13796.0MB
train_loss: 0.893 train cer: 0.233
[Epoch 46] dev_loss_per_frame=0.8026, dev_CER=20.99%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=20.99%)
allocated=60.0MB reserved=13796.0MB
train_loss: 0.881 train cer: 0.243
[Epoch 47] dev_loss_per_frame=0.8166, dev_CER=21.34%
allocated=60.1MB reserved=13796.0MB
train_loss: 0.910 train cer: 0.247
[Epoch 48] dev_loss_per_frame=0.8229, dev_CER=21.51%
allocated=59.8MB reserved=13796.0MB
train_loss: 0.870 train cer: 0.242
[Epoch 49] dev_loss_per_frame=0.7854, dev_CER=20.40%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=20.40%)
allocated=59.8MB reserved=13796.0MB
train_loss: 0.857 train cer: 0.230
[Epoch 50] dev_loss_per_frame=0.8189, dev_CER=21.33%
allocated=59.8MB reserved=13796.0MB
train_loss: 0.862 train cer: 0.235
[Epoch 51] dev_loss_per_frame=0.8009, dev_CER=20.83%
allocated=59.8MB reserved=13796.0MB
train_loss: 0.852 train cer: 0.238
[Epoch 52] dev_loss_per_frame=0.7768, dev_CER=20.25%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=20.25%)
allocated=59.8MB reserved=13796.0MB
train_loss: 0.868 train cer: 0.237
[Epoch 53] dev_loss_per_frame=0.8015, dev_CER=20.85%
allocated=60.0MB reserved=13796.0MB
train_loss: 0.851 train cer: 0.245
[Epoch 54] dev_loss_per_frame=0.7797, dev_CER=20.19%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=20.19%)
allocated=59.8MB reserved=13796.0MB
train_loss: 0.832 train cer: 0.232
[Epoch 55] dev_loss_per_frame=0.7792, dev_CER=20.07%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=20.07%)
allocated=60.2MB reserved=13796.0MB
train_loss: 0.841 train cer: 0.232
[Epoch 56] dev_loss_per_frame=0.7751, dev_CER=19.93%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=19.93%)
allocated=59.8MB reserved=13796.0MB
train_loss: 0.833 train cer: 0.232
[Epoch 57] dev_loss_per_frame=0.8128, dev_CER=21.04%
allocated=60.2MB reserved=13796.0MB
train_loss: 0.834 train cer: 0.245
[Epoch 58] dev_loss_per_frame=0.7515, dev_CER=19.63%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=19.63%)
allocated=59.8MB reserved=13796.0MB
train_loss: 0.804 train cer: 0.214
[Epoch 59] dev_loss_per_frame=0.7530, dev_CER=19.48%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=19.48%)
allocated=59.8MB reserved=13796.0MB
train_loss: 0.813 train cer: 0.225
[Epoch 60] dev_loss_per_frame=0.7557, dev_CER=19.55%
allocated=59.8MB reserved=13796.0MB
train_loss: 0.801 train cer: 0.228
[Epoch 61] dev_loss_per_frame=0.7647, dev_CER=19.66%
allocated=59.8MB reserved=13796.0MB
train_loss: 0.816 train cer: 0.230
[Epoch 62] dev_loss_per_frame=0.8447, dev_CER=21.55%
allocated=60.0MB reserved=13796.0MB
train_loss: 0.808 train cer: 0.229
[Epoch 63] dev_loss_per_frame=0.7587, dev_CER=19.64%
allocated=59.8MB reserved=13796.0MB
train_loss: 0.805 train cer: 0.224
[Epoch 64] dev_loss_per_frame=0.7566, dev_CER=19.32%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=19.32%)
allocated=59.8MB reserved=13796.0MB
train_loss: 0.830 train cer: 0.228
[Epoch 65] dev_loss_per_frame=0.7810, dev_CER=19.91%
old_lr=0.001, new_lr=0.0005
allocated=60.5MB reserved=13796.0MB
train_loss: 0.723 train cer: 0.202
[Epoch 66] dev_loss_per_frame=0.6984, dev_CER=17.85%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=17.85%)
allocated=59.8MB reserved=13796.0MB
train_loss: 0.699 train cer: 0.194
[Epoch 67] dev_loss_per_frame=0.7011, dev_CER=17.98%
allocated=60.5MB reserved=13796.0MB
train_loss: 0.687 train cer: 0.184
[Epoch 68] dev_loss_per_frame=0.6855, dev_CER=17.53%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=17.53%)
allocated=60.0MB reserved=13796.0MB
train_loss: 0.684 train cer: 0.202
[Epoch 69] dev_loss_per_frame=0.6909, dev_CER=17.48%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=17.48%)
allocated=60.5MB reserved=13798.0MB
train_loss: 0.671 train cer: 0.191
[Epoch 70] dev_loss_per_frame=0.6791, dev_CER=17.29%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=17.29%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.668 train cer: 0.186
[Epoch 71] dev_loss_per_frame=0.6820, dev_CER=17.29%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=17.29%)
allocated=59.9MB reserved=13798.0MB
train_loss: 0.657 train cer: 0.178
[Epoch 72] dev_loss_per_frame=0.6818, dev_CER=17.26%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=17.26%)
allocated=59.9MB reserved=13798.0MB
train_loss: 0.654 train cer: 0.194
[Epoch 73] dev_loss_per_frame=0.6802, dev_CER=17.33%
allocated=60.0MB reserved=13798.0MB
train_loss: 0.664 train cer: 0.190
[Epoch 74] dev_loss_per_frame=0.6957, dev_CER=17.49%
allocated=59.9MB reserved=13798.0MB
train_loss: 0.662 train cer: 0.192
[Epoch 75] dev_loss_per_frame=0.6722, dev_CER=16.96%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=16.96%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.660 train cer: 0.184
[Epoch 76] dev_loss_per_frame=0.6932, dev_CER=17.63%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.655 train cer: 0.185
[Epoch 77] dev_loss_per_frame=0.6730, dev_CER=17.13%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.653 train cer: 0.184
[Epoch 78] dev_loss_per_frame=0.6833, dev_CER=17.22%
allocated=60.0MB reserved=13798.0MB
train_loss: 0.646 train cer: 0.170
[Epoch 79] dev_loss_per_frame=0.6706, dev_CER=16.81%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=16.81%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.640 train cer: 0.195
[Epoch 80] dev_loss_per_frame=0.6642, dev_CER=16.84%
allocated=60.1MB reserved=13798.0MB
train_loss: 0.639 train cer: 0.185
[Epoch 81] dev_loss_per_frame=0.6736, dev_CER=17.00%
allocated=60.2MB reserved=13798.0MB
train_loss: 0.651 train cer: 0.170
[Epoch 82] dev_loss_per_frame=0.6768, dev_CER=17.00%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.633 train cer: 0.185
[Epoch 83] dev_loss_per_frame=0.6752, dev_CER=16.95%
allocated=60.6MB reserved=13798.0MB
train_loss: 0.639 train cer: 0.191
[Epoch 84] dev_loss_per_frame=0.6676, dev_CER=16.84%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.647 train cer: 0.183
[Epoch 85] dev_loss_per_frame=0.6789, dev_CER=17.13%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.632 train cer: 0.176
[Epoch 86] dev_loss_per_frame=0.6653, dev_CER=16.82%
allocated=60.3MB reserved=13798.0MB
train_loss: 0.641 train cer: 0.172
[Epoch 87] dev_loss_per_frame=0.6632, dev_CER=16.72%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=16.72%)
allocated=59.9MB reserved=13798.0MB
train_loss: 0.627 train cer: 0.170
[Epoch 88] dev_loss_per_frame=0.6635, dev_CER=16.50%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=16.50%)
allocated=60.4MB reserved=13798.0MB
train_loss: 0.622 train cer: 0.182
[Epoch 89] dev_loss_per_frame=0.6654, dev_CER=16.64%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.618 train cer: 0.170
[Epoch 90] dev_loss_per_frame=0.6564, dev_CER=16.48%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=16.48%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.614 train cer: 0.169
[Epoch 91] dev_loss_per_frame=0.6684, dev_CER=16.83%
allocated=60.0MB reserved=13798.0MB
train_loss: 0.626 train cer: 0.185
[Epoch 92] dev_loss_per_frame=0.6839, dev_CER=16.98%
allocated=60.7MB reserved=13798.0MB
train_loss: 0.630 train cer: 0.180
[Epoch 93] dev_loss_per_frame=0.6615, dev_CER=16.66%
allocated=59.9MB reserved=13798.0MB
train_loss: 0.627 train cer: 0.168
[Epoch 94] dev_loss_per_frame=0.6607, dev_CER=16.52%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.620 train cer: 0.176
[Epoch 95] dev_loss_per_frame=0.6594, dev_CER=16.53%
allocated=59.9MB reserved=13798.0MB
train_loss: 0.627 train cer: 0.172
[Epoch 96] dev_loss_per_frame=0.7008, dev_CER=17.56%
allocated=59.9MB reserved=13798.0MB
train_loss: 0.620 train cer: 0.186
[Epoch 97] dev_loss_per_frame=0.6615, dev_CER=16.49%
old_lr=0.0005, new_lr=0.00025
allocated=59.8MB reserved=13798.0MB
train_loss: 0.571 train cer: 0.163
[Epoch 98] dev_loss_per_frame=0.6341, dev_CER=15.65%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=15.65%)
allocated=60.0MB reserved=13798.0MB
train_loss: 0.557 train cer: 0.164
[Epoch 99] dev_loss_per_frame=0.6312, dev_CER=15.64%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=15.64%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.551 train cer: 0.154
[Epoch 100] dev_loss_per_frame=0.6311, dev_CER=15.52%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=15.52%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.555 train cer: 0.164
[Epoch 101] dev_loss_per_frame=0.6318, dev_CER=15.61%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.549 train cer: 0.173
[Epoch 102] dev_loss_per_frame=0.6348, dev_CER=15.65%
allocated=60.0MB reserved=13798.0MB
train_loss: 0.549 train cer: 0.161
[Epoch 103] dev_loss_per_frame=0.6383, dev_CER=15.65%
allocated=59.9MB reserved=13798.0MB
train_loss: 0.543 train cer: 0.162
[Epoch 104] dev_loss_per_frame=0.6308, dev_CER=15.47%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=15.47%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.547 train cer: 0.164
[Epoch 105] dev_loss_per_frame=0.6310, dev_CER=15.46%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=15.46%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.542 train cer: 0.153
[Epoch 106] dev_loss_per_frame=0.6324, dev_CER=15.50%
allocated=60.1MB reserved=13798.0MB
train_loss: 0.541 train cer: 0.151
[Epoch 107] dev_loss_per_frame=0.6360, dev_CER=15.56%
allocated=59.9MB reserved=13798.0MB
train_loss: 0.546 train cer: 0.158
[Epoch 108] dev_loss_per_frame=0.6295, dev_CER=15.41%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=15.41%)
allocated=60.0MB reserved=13798.0MB
train_loss: 0.538 train cer: 0.155
[Epoch 109] dev_loss_per_frame=0.6368, dev_CER=15.52%
allocated=60.0MB reserved=13798.0MB
train_loss: 0.539 train cer: 0.168
[Epoch 110] dev_loss_per_frame=0.6342, dev_CER=15.50%
allocated=60.2MB reserved=13798.0MB
train_loss: 0.532 train cer: 0.156
[Epoch 111] dev_loss_per_frame=0.6303, dev_CER=15.39%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=15.39%)
allocated=60.8MB reserved=13798.0MB
train_loss: 0.533 train cer: 0.156
[Epoch 112] dev_loss_per_frame=0.6303, dev_CER=15.32%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=15.32%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.531 train cer: 0.153
[Epoch 113] dev_loss_per_frame=0.6320, dev_CER=15.43%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.531 train cer: 0.162
[Epoch 114] dev_loss_per_frame=0.6283, dev_CER=15.29%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=15.29%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.536 train cer: 0.150
[Epoch 115] dev_loss_per_frame=0.6383, dev_CER=15.55%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.535 train cer: 0.160
[Epoch 116] dev_loss_per_frame=0.6277, dev_CER=15.30%
allocated=60.5MB reserved=13798.0MB
train_loss: 0.534 train cer: 0.158
[Epoch 117] dev_loss_per_frame=0.6263, dev_CER=15.31%
allocated=60.6MB reserved=13798.0MB
train_loss: 0.534 train cer: 0.142
[Epoch 118] dev_loss_per_frame=0.6284, dev_CER=15.30%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.533 train cer: 0.150
[Epoch 119] dev_loss_per_frame=0.6314, dev_CER=15.32%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.540 train cer: 0.150
[Epoch 120] dev_loss_per_frame=0.6316, dev_CER=15.35%
allocated=59.9MB reserved=13798.0MB
train_loss: 0.527 train cer: 0.145
[Epoch 121] dev_loss_per_frame=0.6240, dev_CER=15.22%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=15.22%)
allocated=60.1MB reserved=13798.0MB
train_loss: 0.523 train cer: 0.162
[Epoch 122] dev_loss_per_frame=0.6337, dev_CER=15.38%
allocated=60.3MB reserved=13798.0MB
train_loss: 0.528 train cer: 0.144
[Epoch 123] dev_loss_per_frame=0.6275, dev_CER=15.28%
allocated=60.3MB reserved=13798.0MB
train_loss: 0.530 train cer: 0.154
[Epoch 124] dev_loss_per_frame=0.6333, dev_CER=15.40%
allocated=59.9MB reserved=13798.0MB
train_loss: 0.525 train cer: 0.167
[Epoch 125] dev_loss_per_frame=0.6260, dev_CER=15.17%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=15.17%)
allocated=60.0MB reserved=13798.0MB
train_loss: 0.520 train cer: 0.155
[Epoch 126] dev_loss_per_frame=0.6258, dev_CER=15.25%
allocated=60.6MB reserved=13798.0MB
train_loss: 0.527 train cer: 0.147
[Epoch 127] dev_loss_per_frame=0.6315, dev_CER=15.28%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.526 train cer: 0.149
[Epoch 128] dev_loss_per_frame=0.6239, dev_CER=15.09%
old_lr=0.00025, new_lr=0.000125
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=15.09%)
allocated=60.6MB reserved=13798.0MB
train_loss: 0.499 train cer: 0.143
[Epoch 129] dev_loss_per_frame=0.6131, dev_CER=14.80%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=14.80%)
allocated=60.0MB reserved=13798.0MB
train_loss: 0.493 train cer: 0.138
[Epoch 130] dev_loss_per_frame=0.6189, dev_CER=14.88%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.491 train cer: 0.135
[Epoch 131] dev_loss_per_frame=0.6170, dev_CER=14.84%
allocated=59.9MB reserved=13798.0MB
train_loss: 0.492 train cer: 0.150
[Epoch 132] dev_loss_per_frame=0.6155, dev_CER=14.75%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=14.75%)
allocated=60.4MB reserved=13798.0MB
train_loss: 0.490 train cer: 0.142
[Epoch 133] dev_loss_per_frame=0.6172, dev_CER=14.83%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.490 train cer: 0.131
[Epoch 134] dev_loss_per_frame=0.6175, dev_CER=14.78%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.488 train cer: 0.143
[Epoch 135] dev_loss_per_frame=0.6161, dev_CER=14.81%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.484 train cer: 0.141
[Epoch 136] dev_loss_per_frame=0.6139, dev_CER=14.77%
old_lr=0.000125, new_lr=6.25e-05
allocated=59.8MB reserved=13798.0MB
train_loss: 0.478 train cer: 0.146
[Epoch 137] dev_loss_per_frame=0.6121, dev_CER=14.69%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=14.69%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.479 train cer: 0.126
[Epoch 138] dev_loss_per_frame=0.6136, dev_CER=14.62%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=14.62%)
allocated=59.9MB reserved=13798.0MB
train_loss: 0.478 train cer: 0.142
[Epoch 139] dev_loss_per_frame=0.6131, dev_CER=14.59%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=14.59%)
allocated=60.5MB reserved=13798.0MB
train_loss: 0.472 train cer: 0.142
[Epoch 140] dev_loss_per_frame=0.6122, dev_CER=14.61%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.471 train cer: 0.134
[Epoch 141] dev_loss_per_frame=0.6124, dev_CER=14.60%
allocated=60.3MB reserved=13798.0MB
train_loss: 0.471 train cer: 0.135
[Epoch 142] dev_loss_per_frame=0.6115, dev_CER=14.61%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.473 train cer: 0.140
[Epoch 143] dev_loss_per_frame=0.6159, dev_CER=14.60%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.476 train cer: 0.135
[Epoch 144] dev_loss_per_frame=0.6129, dev_CER=14.62%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.475 train cer: 0.141
[Epoch 145] dev_loss_per_frame=0.6119, dev_CER=14.56%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=14.56%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.471 train cer: 0.138
[Epoch 146] dev_loss_per_frame=0.6151, dev_CER=14.58%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.476 train cer: 0.139
[Epoch 147] dev_loss_per_frame=0.6153, dev_CER=14.56%
allocated=60.0MB reserved=13798.0MB
train_loss: 0.471 train cer: 0.127
[Epoch 148] dev_loss_per_frame=0.6114, dev_CER=14.55%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=14.55%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.471 train cer: 0.146
[Epoch 149] dev_loss_per_frame=0.6109, dev_CER=14.52%
  CER 改善，已保存到 saved_models/best_ctc_asr_cer_20251220-173954.pt (best_CER=14.52%)
allocated=59.8MB reserved=13798.0MB
train_loss: 0.468 train cer: 0.137
[Epoch 150] dev_loss_per_frame=0.6128, dev_CER=14.63%
allocated=60.0MB reserved=13798.0MB
train_loss: 0.470 train cer: 0.151
[Epoch 151] dev_loss_per_frame=0.6136, dev_CER=14.57%
allocated=59.9MB reserved=13798.0MB
train_loss: 0.472 train cer: 0.127
[Epoch 152] dev_loss_per_frame=0.6102, dev_CER=14.55%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.472 train cer: 0.129
[Epoch 153] dev_loss_per_frame=0.6105, dev_CER=14.54%
allocated=60.2MB reserved=13798.0MB
train_loss: 0.469 train cer: 0.137
[Epoch 154] dev_loss_per_frame=0.6119, dev_CER=14.57%
allocated=60.2MB reserved=13798.0MB
train_loss: 0.467 train cer: 0.145
[Epoch 155] dev_loss_per_frame=0.6105, dev_CER=14.55%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.464 train cer: 0.132
[Epoch 156] dev_loss_per_frame=0.6111, dev_CER=14.55%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.466 train cer: 0.134
[Epoch 157] dev_loss_per_frame=0.6101, dev_CER=14.56%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.464 train cer: 0.131
[Epoch 158] dev_loss_per_frame=0.6125, dev_CER=14.57%
allocated=59.9MB reserved=13798.0MB
train_loss: 0.464 train cer: 0.141
[Epoch 159] dev_loss_per_frame=0.6115, dev_CER=14.55%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.463 train cer: 0.131
[Epoch 160] dev_loss_per_frame=0.6152, dev_CER=14.57%
allocated=59.8MB reserved=13798.0MB
train_loss: 0.464 train cer: 0.137
[Epoch 161] dev_loss_per_frame=0.6112, dev_CER=14.53%
allocated=59.9MB reserved=13798.0MB
train_loss: 0.469 train cer: 0.136
[Epoch 162] dev_loss_per_frame=0.6118, dev_CER=14.53%
allocated=59.9MB reserved=13798.0MB
train_loss: 0.460 train cer: 0.139
[Epoch 163] dev_loss_per_frame=0.6128, dev_CER=14.55%
allocated=60.0MB reserved=13798.0MB
